{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (78.1.0)\n",
      "Requirement already satisfied: numba in /usr/lib/python3/dist-packages (0.61.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/lib/python3/dist-packages (from numba) (0.44.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.24 in /usr/lib/python3/dist-packages (from numba) (2.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U setuptools numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/flash_attn/ops/triton/layer_norm.py:984: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "/usr/lib/python3/dist-packages/flash_attn/ops/triton/layer_norm.py:1043: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in GPTNeoForCausalLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3680448"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    ")\n",
    "import transformers\n",
    "\n",
    "from datasets import load_dataset\n",
    "from composer import Trainer    \n",
    "from composer.models import HuggingFaceModel, ComposerModel\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ModernBERT.src.sequence_packer import GreedyBestFitSequencePacker\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"roneneldan/TinyStories-1M\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.max_position_embeddings = 1024\n",
    "model = AutoModelForCausalLM.from_config(config, attn_implementation='flash_attention_2').to('cuda')\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = load_dataset('roneneldan/TinyStories', split='train')\n",
    "val_data = load_dataset('roneneldan/TinyStories', split='validation').with_format('np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 2119719, Filtered dataset size: 2119719\n"
     ]
    }
   ],
   "source": [
    "def remove_rows_with_keyword(dataset, keyword):\n",
    "    \"\"\"\n",
    "    Remove rows from a dataset where the 'text' field contains the specified keyword.\n",
    "    \n",
    "    Args:\n",
    "        dataset: A Hugging Face dataset\n",
    "        keyword: String to search for in the text\n",
    "        \n",
    "    Returns:\n",
    "        Filtered dataset without rows containing the keyword\n",
    "    \"\"\"\n",
    "    filtered_indices = [i for i, example in enumerate(dataset) if keyword not in example['text']]\n",
    "    return dataset.select(filtered_indices)\n",
    "\n",
    "# Example usage:\n",
    "keywords_to_filter = [\"drown\", \"violent\", \"died\", \"kill\", \"bad ending\", ]\n",
    "filtered_train_data = train_data\n",
    "for keyword in keywords_to_filter:\n",
    "    # filtered_train_data = remove_rows_with_keyword(filtered_train_data, keyword)\n",
    "    pass\n",
    "    \n",
    "print(f\"Original dataset size: {len(train_data)}, Filtered dataset size: {len(filtered_train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    for start_idx in range(0, len(train_data), 10000):\n",
    "        patch = train_data[start_idx: start_idx+10000]\n",
    "        yield patch['text']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = get_training_corpus()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = tokenizer.train_new_from_iterator(corpus, vocab_size=max_vocab_size)\n",
    "# tokenizer.save_pretrained(f'./training/tokenizer/{max_vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer.from_pretrained(f'./training/tokenizer/{max_vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2048, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <|endoftext|>\n",
      "1 !\n",
      "2 \"\n",
      "3 #\n",
      "4 $\n",
      "5 %\n",
      "6 &\n",
      "7 '\n",
      "8 (\n",
      "9 )\n",
      "10 *\n",
      "11 +\n",
      "12 ,\n",
      "13 -\n",
      "14 .\n",
      "15 /\n",
      "16 0\n",
      "17 1\n",
      "18 2\n",
      "19 3\n",
      "20 4\n",
      "21 5\n",
      "22 6\n",
      "23 7\n",
      "24 8\n",
      "25 9\n",
      "26 :\n",
      "27 ;\n",
      "28 <\n",
      "29 =\n",
      "30 >\n",
      "31 ?\n",
      "32 @\n",
      "33 A\n",
      "34 B\n",
      "35 C\n",
      "36 D\n",
      "37 E\n",
      "38 F\n",
      "39 G\n",
      "40 H\n",
      "41 I\n",
      "42 J\n",
      "43 K\n",
      "44 L\n",
      "45 M\n",
      "46 N\n",
      "47 O\n",
      "48 P\n",
      "49 Q\n",
      "50 R\n",
      "51 S\n",
      "52 T\n",
      "53 U\n",
      "54 V\n",
      "55 W\n",
      "56 X\n",
      "57 Y\n",
      "58 Z\n",
      "59 [\n",
      "60 \\\n",
      "61 ]\n",
      "62 ^\n",
      "63 _\n",
      "64 `\n",
      "65 a\n",
      "66 b\n",
      "67 c\n",
      "68 d\n",
      "69 e\n",
      "70 f\n",
      "71 g\n",
      "72 h\n",
      "73 i\n",
      "74 j\n",
      "75 k\n",
      "76 l\n",
      "77 m\n",
      "78 n\n",
      "79 o\n",
      "80 p\n",
      "81 q\n",
      "82 r\n",
      "83 s\n",
      "84 t\n",
      "85 u\n",
      "86 v\n",
      "87 w\n",
      "88 x\n",
      "89 y\n",
      "90 z\n",
      "91 {\n",
      "92 |\n",
      "93 }\n",
      "94 ~\n",
      "95 ¡\n",
      "96 ¢\n",
      "97 £\n",
      "98 ¤\n",
      "99 ¥\n",
      "100 ¦\n",
      "101 §\n",
      "102 ¨\n",
      "103 ©\n",
      "104 ª\n",
      "105 «\n",
      "106 ¬\n",
      "107 ®\n",
      "108 ¯\n",
      "109 °\n",
      "110 ±\n",
      "111 ²\n",
      "112 ³\n",
      "113 ´\n",
      "114 µ\n",
      "115 ¶\n",
      "116 ·\n",
      "117 ¸\n",
      "118 ¹\n",
      "119 º\n",
      "120 »\n",
      "121 ¼\n",
      "122 ½\n",
      "123 ¾\n",
      "124 ¿\n",
      "125 À\n",
      "126 Á\n",
      "127 Â\n",
      "128 Ã\n",
      "129 Ä\n",
      "130 Å\n",
      "131 Æ\n",
      "132 Ç\n",
      "133 È\n",
      "134 É\n",
      "135 Ê\n",
      "136 Ë\n",
      "137 Ì\n",
      "138 Í\n",
      "139 Î\n",
      "140 Ï\n",
      "141 Ð\n",
      "142 Ñ\n",
      "143 Ò\n",
      "144 Ó\n",
      "145 Ô\n",
      "146 Õ\n",
      "147 Ö\n",
      "148 ×\n",
      "149 Ø\n",
      "150 Ù\n",
      "151 Ú\n",
      "152 Û\n",
      "153 Ü\n",
      "154 Ý\n",
      "155 Þ\n",
      "156 ß\n",
      "157 à\n",
      "158 á\n",
      "159 â\n",
      "160 ã\n",
      "161 ä\n",
      "162 å\n",
      "163 æ\n",
      "164 ç\n",
      "165 è\n",
      "166 é\n",
      "167 ê\n",
      "168 ë\n",
      "169 ì\n",
      "170 í\n",
      "171 î\n",
      "172 ï\n",
      "173 ð\n",
      "174 ñ\n",
      "175 ò\n",
      "176 ó\n",
      "177 ô\n",
      "178 õ\n",
      "179 ö\n",
      "180 ÷\n",
      "181 ø\n",
      "182 ù\n",
      "183 ú\n",
      "184 û\n",
      "185 ü\n",
      "186 ý\n",
      "187 þ\n",
      "188 ÿ\n",
      "189 Ā\n",
      "190 ā\n",
      "191 Ă\n",
      "192 ă\n",
      "193 Ą\n",
      "194 ą\n",
      "195 Ć\n",
      "196 ć\n",
      "197 Ĉ\n",
      "198 ĉ\n",
      "199 Ċ\n",
      "200 ċ\n",
      "201 Č\n",
      "202 č\n",
      "203 Ď\n",
      "204 ď\n",
      "205 Đ\n",
      "206 đ\n",
      "207 Ē\n",
      "208 ē\n",
      "209 Ĕ\n",
      "210 ĕ\n",
      "211 Ė\n",
      "212 ė\n",
      "213 Ę\n",
      "214 ę\n",
      "215 Ě\n",
      "216 ě\n",
      "217 Ĝ\n",
      "218 ĝ\n",
      "219 Ğ\n",
      "220 ğ\n",
      "221 Ġ\n",
      "222 ġ\n",
      "223 Ģ\n",
      "224 ģ\n",
      "225 Ĥ\n",
      "226 ĥ\n",
      "227 Ħ\n",
      "228 ħ\n",
      "229 Ĩ\n",
      "230 ĩ\n",
      "231 Ī\n",
      "232 ī\n",
      "233 Ĭ\n",
      "234 ĭ\n",
      "235 Į\n",
      "236 į\n",
      "237 İ\n",
      "238 ı\n",
      "239 Ĳ\n",
      "240 ĳ\n",
      "241 Ĵ\n",
      "242 ĵ\n",
      "243 Ķ\n",
      "244 ķ\n",
      "245 ĸ\n",
      "246 Ĺ\n",
      "247 ĺ\n",
      "248 Ļ\n",
      "249 ļ\n",
      "250 Ľ\n",
      "251 ľ\n",
      "252 Ŀ\n",
      "253 ŀ\n",
      "254 Ł\n",
      "255 ł\n",
      "256 Ń\n",
      "257 he\n",
      "258 Ġt\n",
      "259 Ġa\n",
      "260 Ġs\n",
      "261 Ġw\n",
      "262 nd\n",
      "263 Ġthe\n",
      "264 ed\n",
      "265 Ġand\n",
      "266 Ġto\n",
      "267 Ġb\n",
      "268 in\n",
      "269 Ġh\n",
      "270 Ġwa\n",
      "271 re\n",
      "272 ou\n",
      "273 Ġf\n",
      "274 it\n",
      "275 Ġl\n",
      "276 Ġc\n",
      "277 Ġd\n",
      "278 er\n",
      "279 Ġhe\n",
      "280 Ġm\n",
      "281 Ġp\n",
      "282 Ġwas\n",
      "283 om\n",
      "284 ĠT\n",
      "285 Ġo\n",
      "286 ay\n",
      "287 ar\n",
      "288 is\n",
      "289 ing\n",
      "290 il\n",
      "291 Ġg\n",
      "292 id\n",
      "293 at\n",
      "294 en\n",
      "295 Ġn\n",
      "296 Ġsa\n",
      "297 Ġha\n",
      "298 ĠS\n",
      "299 ĠThe\n",
      "300 an\n",
      "301 im\n",
      "302 or\n",
      "303 on\n",
      "304 Ġit\n",
      "305 Ġth\n",
      "306 ll\n",
      "307 le\n",
      "308 ĠH\n",
      "309 Ġher\n",
      "310 ot\n",
      "311 et\n",
      "312 ir\n",
      "313 ĠShe\n",
      "314 es\n",
      "315 ĠHe\n",
      "316 Ġin\n",
      "317 ver\n",
      "318 ut\n",
      "319 ow\n",
      "320 ĠThey\n",
      "321 ck\n",
      "322 Ġe\n",
      "323 Ġu\n",
      "324 ld\n",
      "325 Ġy\n",
      "326 oo\n",
      "327 Ġsaid\n",
      "328 ig\n",
      "329 Ġ\"\n",
      "330 ily\n",
      "331 Ġr\n",
      "332 Ġbe\n",
      "333 am\n",
      "334 Ġst\n",
      "335 ĠI\n",
      "336 ce\n",
      "337 ke\n",
      "338 Ġshe\n",
      "339 ve\n",
      "340 pp\n",
      "341 ith\n",
      "342 Ġwith\n",
      "343 Lily\n",
      "344 On\n",
      "345 Ġon\n",
      "346 Ġyou\n",
      "347 Ġof\n",
      "348 ked\n",
      "349 ri\n",
      "350 Ġso\n",
      "351 nt\n",
      "352 Ġhis\n",
      "353 Ġpl\n",
      "354 ad\n",
      "355 very\n",
      "356 Ġday\n",
      "357 Ġthat\n",
      "358 Ġup\n",
      "359 Ġplay\n",
      "360 Ġhad\n",
      "361 st\n",
      "362 Ġthey\n",
      "363 Ġwe\n",
      "364 ĠLily\n",
      "365 Ġmom\n",
      "366 Ġfor\n",
      "367 ĠB\n",
      "368 el\n",
      "369 un\n",
      "370 ould\n",
      "371 's\n",
      "372 my\n",
      "373 The\n",
      "374 Ġli\n",
      "375 ch\n",
      "376 ent\n",
      "377 Ġhapp\n",
      "378 Ġwant\n",
      "379 itt\n",
      "380 Ġsh\n",
      "381 out\n",
      "382 her\n",
      "383 Ġdo\n",
      "384 ly\n",
      "385 Ġnot\n",
      "386 ome\n",
      "387 se\n",
      "388 Ġvery\n",
      "389 ound\n",
      "390 end\n",
      "391 all\n",
      "392 Ġwh\n",
      "393 ime\n",
      "394 ittle\n",
      "395 Ġk\n",
      "396 Ġtime\n",
      "397 Ġlittle\n",
      "398 al\n",
      "399 Ġthere\n",
      "400 Ġne\n",
      "401 ht\n",
      "402 ĠM\n",
      "403 Ġre\n",
      "404 Ġhappy\n",
      "405 Ġsm\n",
      "406 Ġbig\n",
      "407 Ġis\n",
      "408 ĠĊ\n",
      "409 ĠIt\n",
      "410 Ġbut\n",
      "411 ack\n",
      "412 Ġan\n",
      "413 Ġsaw\n",
      "414 riend\n",
      "415 .\"\n",
      "416 Ġfriend\n",
      "417 ry\n",
      "418 Ġas\n",
      "419 ra\n",
      "420 One\n",
      "421 ide\n",
      "422 ake\n",
      "423 't\n",
      "424 !\"\n",
      "425 ug\n",
      "426 Ġloo\n",
      "427 ved\n",
      "428 ter\n",
      "429 Ġwere\n",
      "430 ore\n",
      "431 Once\n",
      "432 Ġlo\n",
      "433 ec\n",
      "434 Ġhim\n",
      "435 Ġtoo\n",
      "436 Ġgo\n",
      "437 Ġbo\n",
      "438 Ġse\n",
      "439 irl\n",
      "440 Ġare\n",
      "441 Ġj\n",
      "442 ĠTim\n",
      "443 ard\n",
      "444 Ġwanted\n",
      "445 ill\n",
      "446 Ġgirl\n",
      "447 Ġupon\n",
      "448 Ġthem\n",
      "449 Ġout\n",
      "450 Ġat\n",
      "451 ur\n",
      "452 ind\n",
      "453 Ġtheir\n",
      "454 fu\n",
      "455 Ġsp\n",
      "456 way\n",
      "457 ĠA\n",
      "458 Ġsmil\n",
      "459 Ġdid\n",
      "460 Ġcould\n",
      "461 hen\n",
      "462 Ġhave\n",
      "463 ain\n",
      "464 art\n",
      "465 Ġex\n",
      "466 hed\n",
      "467 rom\n",
      "468 Ġwent\n",
      "469 Ġar\n",
      "470 ic\n",
      "471 Ġcan\n",
      "472 ĠJ\n",
      "473 lp\n",
      "474 ful\n",
      "475 ĠBen\n",
      "476 ood\n",
      "477 ?\"\n",
      "478 hing\n",
      "479 Ġfriends\n",
      "480 Ġnam\n",
      "481 ight\n",
      "482 Ġall\n",
      "483 Ġhelp\n",
      "484 Ġkn\n",
      "485 um\n",
      "486 one\n",
      "487 ark\n",
      "488 Ġback\n",
      "489 Ġsay\n",
      "490 You\n",
      "491 Ġfun\n",
      "492 Ġcl\n",
      "493 ĠTom\n",
      "494 are\n",
      "495 Ġno\n",
      "496 Ġle\n",
      "497 op\n",
      "498 Ġsmiled\n",
      "499 Ġsc\n",
      "500 Ġnamed\n",
      "501 Ġal\n",
      "502 oug\n",
      "503 Ġloved\n",
      "504 side\n",
      "505 elt\n",
      "506 ĠOne\n",
      "507 Ġman\n",
      "508 Ġasked\n",
      "509 ick\n",
      "510 Ġtoy\n",
      "511 Ġlike\n",
      "512 Ġfe\n",
      "513 Ġfelt\n",
      "514 Ġlooked\n",
      "515 Ġsome\n",
      "516 Ġaround\n",
      "517 Ġsee\n",
      "518 Ġme\n",
      "519 ame\n",
      "520 omet\n",
      "521 ĠW\n",
      "522 Ġro\n",
      "523 Ġbr\n",
      "524 ure\n",
      "525 ĠTimmy\n",
      "526 Ġbir\n",
      "527 get\n",
      "528 ice\n",
      "529 Ġboy\n",
      "530 Ġwould\n",
      "531 Ġstart\n",
      "532 ong\n",
      "533 Ã¢\n",
      "534 âĤ\n",
      "535 âĤ¬\n",
      "536 ss\n",
      "537 Ġbird\n",
      "538 Ġsomet\n",
      "539 Ġfa\n",
      "540 dd\n",
      "541 ings\n",
      "542 Ġag\n",
      "543 Ġwor\n",
      "544 Ġwhat\n",
      "545 ade\n",
      "546 Ġmake\n",
      "547 king\n",
      "548 ,\"\n",
      "549 ie\n",
      "550 ĠBut\n",
      "551 own\n",
      "552 Ġtre\n",
      "553 Ġran\n",
      "554 gether\n",
      "555 ĠYou\n",
      "556 Ġaway\n",
      "557 ag\n",
      "558 ared\n",
      "559 Ġsays\n",
      "560 Ġstarted\n",
      "561 oud\n",
      "562 if\n",
      "563 Ġmade\n",
      "564 Ġcar\n",
      "565 Ġsomething\n",
      "566 Ġtogether\n",
      "567 ited\n",
      "568 ther\n",
      "569 Ġpark\n",
      "570 Ġco\n",
      "571 Ġsad\n",
      "572 Ġother\n",
      "573 Ġnew\n",
      "574 Ġexc\n",
      "575 Ġput\n",
      "576 Ġfrom\n",
      "577 Ġpr\n",
      "578 ell\n",
      "579 ĠL\n",
      "580 Ġla\n",
      "581 Ġhug\n",
      "582 ble\n",
      "583 Ġmu\n",
      "584 ook\n",
      "585 ach\n",
      "586 Ġagain\n",
      "587 Ġhome\n",
      "588 Ġwhen\n",
      "589 Ġgood\n",
      "590 hat\n",
      "591 ep\n",
      "592 Ġwho\n",
      "593 est\n",
      "594 ried\n",
      "595 Ġfound\n",
      "596 Ġfl\n",
      "597 Ġthen\n",
      "598 Ġch\n",
      "599 Ġdec\n",
      "600 pped\n",
      "601 Ġwal\n",
      "602 as\n",
      "603 Ġget\n",
      "604 qu\n",
      "605 Ġplaying\n",
      "606 ought\n",
      "607 pl\n",
      "608 ĠE\n",
      "609 ally\n",
      "610 Ġsw\n",
      "611 ous\n",
      "612 nn\n",
      "613 Ġthings\n",
      "614 Ġexcited\n",
      "615 Ġliked\n",
      "616 Ġgot\n",
      "617 uck\n",
      "618 ro\n",
      "619 ided\n",
      "620 Ġdecided\n",
      "621 Ġbl\n",
      "622 ave\n",
      "623 Ġcame\n",
      "624 Ġevery\n",
      "625 ara\n",
      "626 Ġyour\n",
      "627 ĠD\n",
      "628 ĠMom\n",
      "629 ax\n",
      "630 Ġv\n",
      "631 Ġscared\n",
      "632 ust\n",
      "633 Ġone\n",
      "634 Ġdog\n",
      "635 Ġdown\n",
      "636 ouse\n",
      "637 ny\n",
      "638 Ġfind\n",
      "639 Ġcare\n",
      "640 Ġbec\n",
      "641 ist\n",
      "642 Ġthan\n",
      "643 Ġfeel\n",
      "644 ap\n",
      "645 ue\n",
      "646 udd\n",
      "647 nna\n",
      "648 Ġdad\n",
      "649 Ġab\n",
      "650 They\n",
      "651 Ġmy\n",
      "652 Ġlook\n",
      "653 Ġke\n",
      "654 our\n",
      "655 Ġwill\n",
      "656 arn\n",
      "657 Ġgr\n",
      "658 us\n",
      "659 nder\n",
      "660 Ġgra\n",
      "661 ways\n",
      "662 ess\n",
      "663 Ġdidn\n",
      "664 Ġpo\n",
      "665 fe\n",
      "666 Ġalways\n",
      "667 Ġtook\n",
      "668 Ġabout\n",
      "669 ant\n",
      "670 bb\n",
      "671 Ġlot\n",
      "672 Ġmommy\n",
      "673 Ġtoys\n",
      "674 Ġkne\n",
      "675 ers\n",
      "676 ise\n",
      "677 ite\n",
      "678 Ġoutside\n",
      "679 Ġtree\n",
      "680 Ġthought\n",
      "681 Ġball\n",
      "682 ĠF\n",
      "683 Ġmore\n",
      "684 eci\n",
      "685 ĠSam\n",
      "686 ened\n",
      "687 ched\n",
      "688 Ġta\n",
      "689 Ġold\n",
      "690 Ġho\n",
      "691 Ġlearn\n",
      "692 ret\n",
      "693 Ġint\n",
      "694 ged\n",
      "695 Ġknow\n",
      "696 Ġlaug\n",
      "697 Ġtake\n",
      "698 ecial\n",
      "699 Ġspecial\n",
      "700 Ġsor\n",
      "701 Ġcat\n",
      "702 udden\n",
      "703 Ġknew\n",
      "704 ĠMax\n",
      "705 ive\n",
      "706 ia\n",
      "707 Ġpe\n",
      "708 Ġany\n",
      "709 uddenly\n",
      "710 Ġtr\n",
      "711 fter\n",
      "712 Ġhow\n",
      "713 ma\n",
      "714 Ġshow\n",
      "715 ink\n",
      "716 Ġsorry\n",
      "717 Ġtw\n",
      "718 But\n",
      "719 Ġmuch\n",
      "720 au\n",
      "721 ish\n",
      "722 Ġrun\n",
      "723 and\n",
      "724 Ġhand\n",
      "725 Ġsl\n",
      "726 ven\n",
      "727 Ġhouse\n",
      "728 Ġor\n",
      "729 Ġop\n",
      "730 Ġsk\n",
      "731 Ġmo\n",
      "732 Ġclo\n",
      "733 Ġsun\n",
      "734 Ġinto\n",
      "735 Ġtried\n",
      "736 Ġinside\n",
      "737 ate\n",
      "738 Ġtold\n",
      "739 Ġwater\n",
      "740 Ġthis\n",
      "741 Ġen\n",
      "742 ank\n",
      "743 Ġif\n",
      "744 Ġproud\n",
      "745 ump\n",
      "746 Ġqu\n",
      "747 Ġover\n",
      "748 Ġcouldn\n",
      "749 Tom\n",
      "750 dy\n",
      "751 Ġgave\n",
      "752 Ġheard\n",
      "753 ĠSara\n",
      "754 Ġnever\n",
      "755 by\n",
      "756 Ġeach\n",
      "757 ace\n",
      "758 Ġroom\n",
      "759 ty\n",
      "760 Ġexpl\n",
      "761 ĠEvery\n",
      "762 Ġeat\n",
      "763 ĠWe\n",
      "764 other\n",
      "765 ause\n",
      "766 Ġpick\n",
      "767 ion\n",
      "768 Ġpret\n",
      "769 ĠAnna\n",
      "770 Mom\n",
      "771 Ġplayed\n",
      "772 ge\n",
      "773 etter\n",
      "774 Ġjust\n",
      "775 ak\n",
      "776 Ġhugged\n",
      "777 Ġgre\n",
      "778 here\n",
      "779 Ġoff\n",
      "780 Ġcom\n",
      "781 Ġwat\n",
      "782 oth\n",
      "783 Ġbox\n",
      "784 Ġnice\n",
      "785 'm\n",
      "786 Ġstr\n",
      "787 Ġbecause\n",
      "788 Ġneed\n",
      "789 ile\n",
      "790 Ġmany\n",
      "791 Ġfo\n",
      "792 uc\n",
      "793 Ġjo\n",
      "794 Ġbear\n",
      "795 Ġsmall\n",
      "796 iz\n",
      "797 Ġbu\n",
      "798 ving\n",
      "799 Ġlong\n",
      "800 ine\n",
      "801 gry\n",
      "802 imal\n",
      "803 ort\n",
      "804 Ġanimal\n",
      "805 Ġsn\n",
      "806 ough\n",
      "807 Ġtry\n",
      "808 Ġunt\n",
      "809 ild\n",
      "810 sel\n",
      "811 urt\n",
      "812 Ġuntil\n",
      "813 ĠJack\n",
      "814 sed\n",
      "815 Ġkind\n",
      "816 Ġlearned\n",
      "817 Ġim\n",
      "818 Ġlove\n",
      "819 Ġbetter\n",
      "820 ft\n",
      "821 Ġflow\n",
      "822 Ġcall\n",
      "823 Ġdon\n",
      "824 He\n",
      "825 ĠJo\n",
      "826 Ġend\n",
      "827 Ġad\n",
      "828 ull\n",
      "829 Ġbest\n",
      "830 vent\n",
      "831 Yes\n",
      "832 ars\n",
      "833 urp\n",
      "834 ady\n",
      "835 em\n",
      "836 ream\n",
      "837 aut\n",
      "838 urn\n",
      "839 ĠMia\n",
      "840 Ġcle\n",
      "841 ĠAnd\n",
      "842 ves\n",
      "843 Åĵ\n",
      "844 arden\n",
      "845 ĠC\n",
      "846 Ġgarden\n",
      "847 Ġfast\n",
      "848 Ġcareful\n",
      "849 ber\n",
      "850 Ġbeaut\n",
      "851 lly\n",
      "852 Th\n",
      "853 Ġeven\n",
      "854 pt\n",
      "855 Ġbra\n",
      "856 ies\n",
      "857 Ġthanked\n",
      "858 Ġfi\n",
      "859 ĠSo\n",
      "860 Ġche\n",
      "861 Ġlaughed\n",
      "862 Ġsky\n",
      "863 Ġby\n",
      "864 It\n",
      "865 ĠHer\n",
      "866 Ġjump\n",
      "867 Ġgl\n",
      "868 ase\n",
      "869 Ġte\n",
      "870 Ġloud\n",
      "871 self\n",
      "872 iny\n",
      "873 Ġway\n",
      "874 wn\n",
      "875 Ġbeauti\n",
      "876 Ġcome\n",
      "877 lew\n",
      "878 Ġlist\n",
      "879 Ġwo\n",
      "880 Ġbeautiful\n",
      "881 Ġhard\n",
      "882 Ġlots\n",
      "883 Ġra\n",
      "884 Ġstill\n",
      "885 Ġfam\n",
      "886 Ġanimals\n",
      "887 ĠÃ¢\n",
      "888 Ġhurt\n",
      "889 Ġunder\n",
      "890 ĠThen\n",
      "891 ect\n",
      "892 Ġstay\n",
      "893 ning\n",
      "894 Ġlet\n",
      "895 ct\n",
      "896 Ġboth\n",
      "897 Ġcu\n",
      "898 ĠHis\n",
      "899 hes\n",
      "900 be\n",
      "901 Ġsafe\n",
      "902 ĠFrom\n",
      "903 ool\n",
      "904 ree\n",
      "905 Ġcol\n",
      "906 Ġtwo\n",
      "907 Ġbad\n",
      "908 Ġbook\n",
      "909 Ġimp\n",
      "910 ople\n",
      "911 Ġrem\n",
      "912 ane\n",
      "913 Ġlived\n",
      "914 kay\n",
      "915 ock\n",
      "916 ucy\n",
      "917 Ġwalked\n",
      "918 Tim\n",
      "919 ast\n",
      "920 urpr\n",
      "921 Ġbrave\n",
      "922 Ġshould\n",
      "923 Ġits\n",
      "924 ob\n",
      "925 ished\n",
      "926 Ġangry\n",
      "927 Ġsurpr\n",
      "928 Ġfamily\n",
      "929 ress\n",
      "930 igh\n",
      "931 When\n",
      "932 Ġpeople\n",
      "933 Ġflew\n",
      "934 Ġcalled\n",
      "935 No\n",
      "936 Ġred\n",
      "937 Ġstor\n",
      "938 ip\n",
      "939 Ġsoon\n",
      "940 Ġfin\n",
      "941 hn\n",
      "942 Let\n",
      "943 led\n",
      "944 Ġkept\n",
      "945 Ġfore\n",
      "946 fore\n",
      "947 Ġdan\n",
      "948 Ġshare\n",
      "949 Ġfly\n",
      "950 xt\n",
      "951 ised\n",
      "952 dded\n",
      "953 Ġpic\n",
      "954 âĤ¬â\n",
      "955 Ġdoor\n",
      "956 Ġgoing\n",
      "957 ĠP\n",
      "958 ĠWhen\n",
      "959 Ġpretty\n",
      "960 Ġkeep\n",
      "961 Ġnow\n",
      "962 Ġrock\n",
      "963 Ġclean\n",
      "964 Ġdra\n",
      "965 ary\n",
      "966 Ġadvent\n",
      "967 ummy\n",
      "968 Ġnoise\n",
      "969 Ġopened\n",
      "970 Ġshiny\n",
      "971 age\n",
      "972 Ġexplore\n",
      "973 Ġwind\n",
      "974 Ġdoll\n",
      "975 Ġcry\n",
      "976 Ġcon\n",
      "977 Ġide\n",
      "978 Ġbefore\n",
      "979 ied\n",
      "980 Ben\n",
      "981 illy\n",
      "982 Ġreal\n",
      "983 Ġsto\n",
      "984 so\n",
      "985 What\n",
      "986 Ġground\n",
      "987 Ġalso\n",
      "988 les\n",
      "989 Ġturn\n",
      "990 Ħ¢\n",
      "991 âĤ¬âĦ¢\n",
      "992 Ġey\n",
      "993 That\n",
      "994 Ġfar\n",
      "995 Ġidea\n",
      "996 Ġfr\n",
      "997 oon\n",
      "998 Ġnodded\n",
      "999 Ġcolor\n",
      "1000 Ġwar\n",
      "1001 oy\n",
      "1002 Ġfeeling\n",
      "1003 Ġun\n",
      "1004 Ġpicked\n",
      "1005 imb\n",
      "1006 th\n",
      "1007 ĠLucy\n",
      "1008 Ġnext\n",
      "1009 Ġwalking\n",
      "1010 thing\n",
      "1011 ture\n",
      "1012 ĠDad\n",
      "1013 Ġclimb\n",
      "1014 Ġhas\n",
      "1015 uch\n",
      "1016 Ġma\n",
      "1017 Ġthr\n",
      "1018 Ġwhile\n",
      "1019 eet\n",
      "1020 Ġbed\n",
      "1021 Ġadventure\n",
      "1022 Ġsmile\n",
      "1023 kes\n",
      "1024 aybe\n",
      "1025 Thank\n",
      "1026 iced\n",
      "1027 ger\n",
      "1028 ious\n",
      "1029 ĠG\n",
      "1030 Ġbeing\n",
      "1031 Ġdif\n",
      "1032 Ġwr\n",
      "1033 Ġclos\n",
      "1034 Ġfood\n",
      "1035 joy\n",
      "1036 ted\n",
      "1037 Ġgive\n",
      "1038 Ġpicture\n",
      "1039 Ġthink\n",
      "1040 ĠSp\n",
      "1041 Ġlooking\n",
      "1042 Ġdel\n",
      "1043 ff\n",
      "1044 ac\n",
      "1045 Ġtruck\n",
      "1046 Ġwait\n",
      "1047 Ġeyes\n",
      "1048 ught\n",
      "1049 Ġtow\n",
      "1050 ting\n",
      "1051 Ġrepl\n",
      "1052 Ġbro\n",
      "1053 Ġstopped\n",
      "1054 Ġlisten\n",
      "1055 Ġafter\n",
      "1056 Ġbre\n",
      "1057 Ġown\n",
      "1058 Ġvo\n",
      "1059 Ġwalk\n",
      "1060 ember\n",
      "1061 ĠSuddenly\n",
      "1062 Ġwonder\n",
      "1063 Ġgreat\n",
      "1064 Ġhands\n",
      "1065 Suddenly\n",
      "1066 Ġshout\n",
      "1067 Ġhead\n",
      "1068 Ġenjoy\n",
      "1069 Ġimport\n",
      "1070 Ġflowers\n",
      "1071 Ġever\n",
      "1072 Ġnoticed\n",
      "1073 Ġblue\n",
      "1074 Ġforest\n",
      "1075 bbit\n",
      "1076 She\n",
      "1077 ized\n",
      "1078 Ġapp\n",
      "1079 irst\n",
      "1080 Ġnear\n",
      "1081 Ġquick\n",
      "1082 Ġdis\n",
      "1083 Ġde\n",
      "1084 able\n",
      "1085 Ġimportant\n",
      "1086 Ġremember\n",
      "1087 Ġfish\n",
      "1088 llow\n",
      "1089 Ġsound\n",
      "1090 Ġslide\n",
      "1091 Ġus\n",
      "1092 maz\n",
      "1093 Ġreplied\n",
      "1094 Ġamaz\n",
      "1095 Ġac\n",
      "1096 lease\n",
      "1097 Ġwork\n",
      "1098 Ġwatch\n",
      "1099 Ġrain\n",
      "1100 Ġshowed\n",
      "1101 Ġrabbit\n",
      "1102 Ġokay\n",
      "1103 gan\n",
      "1104 Ġtal\n",
      "1105 bye\n",
      "1106 fere\n",
      "1107 bbed\n",
      "1108 Ġask\n",
      "1109 Ġdiffere\n",
      "1110 Ġmean\n",
      "1111 Ġright\n",
      "1112 Ġye\n",
      "1113 day\n",
      "1114 Ġwatched\n",
      "1115 Ġbright\n",
      "1116 Ġfollow\n",
      "1117 We\n",
      "1118 ĠSpot\n",
      "1119 So\n",
      "1120 Ġeveryone\n",
      "1121 Ġstrong\n",
      "1122 Ġsqu\n",
      "1123 Ġstick\n",
      "1124 Ġuse\n",
      "1125 Ġbeen\n",
      "1126 Ġmor\n",
      "1127 Ġvoice\n",
      "1128 Ġtra\n",
      "1129 ered\n",
      "1130 Ġquickly\n",
      "1131 ath\n",
      "1132 Ġour\n",
      "1133 Ġwhere\n",
      "1134 Ġyell\n",
      "1135 ĠN\n",
      "1136 ĠMommy\n",
      "1137 Anna\n",
      "1138 Ġdifferent\n",
      "1139 ĠBob\n",
      "1140 Ġchild\n",
      "1141 Ġcuri\n",
      "1142 Ġboat\n",
      "1143 ng\n",
      "1144 Ġsure\n",
      "1145 ĠSue\n",
      "1146 Ġbecame\n",
      "1147 Ġgoodbye\n",
      "1148 Ġface\n",
      "1149 Ġplace\n",
      "1150 ange\n",
      "1151 Ġhop\n",
      "1152 Ġhigh\n",
      "1153 Ġam\n",
      "1154 Look\n",
      "1155 aught\n",
      "1156 ĠR\n",
      "1157 Ġcloser\n",
      "1158 Ġstore\n",
      "1159 Ġwarm\n",
      "1160 Ġdoes\n",
      "1161 Ġcr\n",
      "1162 Ġdress\n",
      "1163 Sara\n",
      "1164 unny\n",
      "1165 Ġcurious\n",
      "1166 Ġmag\n",
      "1167 ila\n",
      "1168 Jo\n",
      "1169 Ġcook\n",
      "1170 Ġbel\n",
      "1171 Ġforg\n",
      "1172 Ġtell\n",
      "1173 Ġfav\n",
      "1174 ndma\n",
      "1175 ass\n",
      "1176 ount\n",
      "1177 co\n",
      "1178 Ġthree\n",
      "1179 leep\n",
      "1180 Ġnight\n",
      "1181 Ġopen\n",
      "1182 Ġcake\n",
      "1183 more\n",
      "1184 Ġhere\n",
      "1185 Ġanymore\n",
      "1186 Ġblock\n",
      "1187 Ġfirst\n",
      "1188 itc\n",
      "1189 Ġbus\n",
      "1190 Ġpull\n",
      "1191 iss\n",
      "1192 ached\n",
      "1193 Her\n",
      "1194 ired\n",
      "1195 Ġbutter\n",
      "1196 Ġz\n",
      "1197 imes\n",
      "1198 ĠTh\n",
      "1199 orn\n",
      "1200 Ġsweet\n",
      "1201 Ġpain\n",
      "1202 Ġkid\n",
      "1203 Ġgrabbed\n",
      "1204 Can\n",
      "1205 Ġpu\n",
      "1206 isy\n",
      "1207 Ġonly\n",
      "1208 Ġmon\n",
      "1209 Ġlea\n",
      "1210 Ġfell\n",
      "1211 Ġba\n",
      "1212 Ġru\n",
      "1213 Ġcont\n",
      "1214 Ġbirds\n",
      "1215 Ġjumped\n",
      "1216 Ġglad\n",
      "1217 Ġbit\n",
      "1218 Ġsand\n",
      "1219 itchen\n",
      "1220 Ġkitchen\n",
      "1221 Ġhelped\n",
      "1222 Ġsees\n",
      "1223 Ġfire\n",
      "1224 Ġper\n",
      "1225 Ġflo\n",
      "1226 Ġstop\n",
      "1227 ĠSarah\n",
      "1228 Ġhappened\n",
      "1229 Ġsing\n",
      "1230 Ġgrass\n",
      "1231 Ġbunny\n",
      "1232 Ġshouted\n",
      "1233 Ġstory\n",
      "1234 ĠLet\n",
      "1235 Ġtri\n",
      "1236 nts\n",
      "1237 Ġdr\n",
      "1238 air\n",
      "1239 After\n",
      "1240 ĠJane\n",
      "1241 ppy\n",
      "1242 Ġreached\n",
      "1243 Ġbeh\n",
      "1244 Ġrealized\n",
      "1245 Ġyummy\n",
      "1246 Ġbrother\n",
      "1247 ĠDo\n",
      "1248 Ġlady\n",
      "1249 Ġmum\n",
      "1250 Ġhaving\n",
      "1251 Ġprin\n",
      "1252 ins\n",
      "1253 Ġfavor\n",
      "1254 ĠAs\n",
      "1255 're\n",
      "1256 Ġmess\n",
      "1257 Ġfavorite\n",
      "1258 Ġdraw\n",
      "1259 Ġcre\n",
      "1260 Ġrest\n",
      "1261 Ġthrough\n",
      "1262 Ġgame\n",
      "1263 Ġhat\n",
      "1264 Ġate\n",
      "1265 Ġless\n",
      "1266 Ġunderst\n",
      "1267 akes\n",
      "1268 ĠEveryone\n",
      "1269 Ġsoft\n",
      "1270 Ġpare\n",
      "1271 zy\n",
      "1272 Ġthing\n",
      "1273 Ġreally\n",
      "1274 ather\n",
      "1275 Ġready\n",
      "1276 Mommy\n",
      "1277 Ġbegan\n",
      "1278 where\n",
      "1279 Ġpretend\n",
      "1280 ĠCan\n",
      "1281 Ġworld\n",
      "1282 ĠJoe\n",
      "1283 ĠThat\n",
      "1284 Ġlooks\n",
      "1285 ken\n",
      "1286 Ġhimself\n",
      "1287 Ġmagic\n",
      "1288 fully\n",
      "1289 Ġpap\n",
      "1290 Ġdone\n",
      "1291 Ġbutterf\n",
      "1292 Ġmaking\n",
      "1293 Ġcut\n",
      "1294 Ġcoming\n",
      "1295 Ġduck\n",
      "1296 ater\n",
      "1297 Ġpond\n",
      "1298 Ġkids\n",
      "1299 Ġwaved\n",
      "1300 Ġwhy\n",
      "1301 Ġprom\n",
      "1302 Ġtired\n",
      "1303 Ġfro\n",
      "1304 Ġfix\n",
      "1305 olly\n",
      "1306 ster\n",
      "1307 Ġmouse\n",
      "1308 Ġworry\n",
      "1309 Ġpart\n",
      "1310 Ġcars\n",
      "1311 Ġste\n",
      "1312 Ġdelic\n",
      "1313 Ġname\n",
      "1314 Ġflower\n",
      "1315 ign\n",
      "1316 Ġfill\n",
      "1317 Wow\n",
      "1318 aisy\n",
      "1319 Ġtouch\n",
      "1320 eddy\n",
      "1321 Ġfunny\n",
      "1322 Ġcatch\n",
      "1323 bo\n",
      "1324 Ġused\n",
      "1325 sh\n",
      "1326 Ġseen\n",
      "1327 Ġhair\n",
      "1328 ĠJohn\n",
      "1329 Ġtast\n",
      "1330 ient\n",
      "1331 Ġtop\n",
      "1332 Ġparents\n",
      "1333 rel\n",
      "1334 Ġanother\n",
      "1335 Ġhold\n",
      "1336 Ġhopped\n",
      "1337 Ġcried\n",
      "1338 iver\n",
      "1339 uff\n",
      "1340 oney\n",
      "1341 mer\n",
      "1342 Ġdoing\n",
      "1343 Ġcool\n",
      "1344 Ġblocks\n",
      "1345 hy\n",
      "1346 \".\n",
      "1347 Ġpus\n",
      "1348 Ġsurprise\n",
      "1349 Ġlight\n",
      "1350 Ġgreen\n",
      "1351 As\n",
      "1352 Ġthank\n",
      "1353 Ġlesson\n",
      "1354 Timmy\n",
      "1355 ation\n",
      "1356 Ġread\n",
      "1357 Ġfloor\n",
      "1358 Ġdin\n",
      "1359 Ġgi\n",
      "1360 Ġwood\n",
      "1361 Ġfull\n",
      "1362 Don\n",
      "1363 Ġdri\n",
      "1364 ards\n",
      "1365 Ġtrees\n",
      "1366 Ġrunning\n",
      "1367 Ġwindow\n",
      "1368 Ġworked\n",
      "1369 Ġyears\n",
      "1370 Ġcra\n",
      "1371 Ġdro\n",
      "1372 Ġ-\n",
      "1373 Ġdark\n",
      "1374 Ġbehind\n",
      "1375 Ġlikes\n",
      "1376 Ġsmell\n",
      "1377 Ġspot\n",
      "1378 Ġwished\n",
      "1379 Ġpaper\n",
      "1380 ued\n",
      "1381 Ġyellow\n",
      "1382 andy\n",
      "1383 Ġbow\n",
      "1384 ul\n",
      "1385 ren\n",
      "1386 Ġswim\n",
      "1387 John\n",
      "1388 Ġhappily\n",
      "1389 Ġbag\n",
      "1390 Ġsat\n",
      "1391 Ġsho\n",
      "1392 Sam\n",
      "1393 Ġsleep\n",
      "1394 aring\n",
      "1395 Ġsurprised\n",
      "1396 ely\n",
      "1397 Ġfrog\n",
      "1398 Ġbutterfly\n",
      "1399 ike\n",
      "1400 Ġswing\n",
      "1401 Ġset\n",
      "1402 Ġcarefully\n",
      "1403 ĠIn\n",
      "1404 Ġslow\n",
      "1405 Ġremembered\n",
      "1406 Ġlost\n",
      "1407 Ġcold\n",
      "1408 Ġheld\n",
      "1409 ello\n",
      "1410 Hello\n",
      "1411 Ġhole\n",
      "1412 Ġice\n",
      "1413 Ġlaugh\n",
      "1414 rew\n",
      "1415 Ġneeded\n",
      "1416 Ġbuy\n",
      "1417 Ġperf\n",
      "1418 Ġleft\n",
      "1419 ons\n",
      "1420 Ġmove\n",
      "1421 reed\n",
      "1422 cess\n",
      "1423 Ġanything\n",
      "1424 Ġdream\n",
      "1425 Ġtall\n",
      "1426 Ġenjoyed\n",
      "1427 Ġwrong\n",
      "1428 Ġarri\n",
      "1429 uit\n",
      "1430 Ġhear\n",
      "1431 Ġfair\n",
      "1432 Ġair\n",
      "1433 Ġfollowed\n",
      "1434 inally\n",
      "1435 Ġbooks\n",
      "1436 ross\n",
      "1437 Ġel\n",
      "1438 Ġchildren\n",
      "1439 Ġhun\n",
      "1440 Ġdelicious\n",
      "1441 Ġtable\n",
      "1442 Ġfinished\n",
      "1443 Ġcontin\n",
      "1444 Ġfriendly\n",
      "1445 Ġdir\n",
      "1446 Ġhot\n",
      "1447 Ġsnow\n",
      "1448 Ġherself\n",
      "1449 ds\n",
      "1450 lf\n",
      "1451 ĠAfter\n",
      "1452 Ġhill\n",
      "1453 ens\n",
      "1454 Ġunderstand\n",
      "1455 Ġplease\n",
      "1456 Ġclose\n",
      "1457 ined\n",
      "1458 Ġhid\n",
      "1459 Ġarrived\n",
      "1460 Ġcast\n",
      "1461 Ġelse\n",
      "1462 Ġarm\n",
      "1463 Ġbaby\n",
      "1464 Ġwonderful\n",
      "1465 Ġmight\n",
      "1466 Ġgent\n",
      "1467 Ġtight\n",
      "1468 Ġforgot\n",
      "1469 sp\n",
      "1470 ield\n",
      "1471 Ġbug\n",
      "1472 ĠSally\n",
      "1473 Ġcolors\n",
      "1474 Ġrel\n",
      "1475 Ġbuild\n",
      "1476 Ġbroken\n",
      "1477 ĠDaisy\n",
      "1478 Ġable\n",
      "1479 Ġgone\n",
      "1480 av\n",
      "1481 ner\n",
      "1482 ĠNow\n",
      "1483 ĠBenny\n",
      "1484 ĠLila\n",
      "1485 Ġyes\n",
      "1486 atter\n",
      "1487 Ġsong\n",
      "1488 Then\n",
      "1489 ich\n",
      "1490 Ġwall\n",
      "1491 Ġsquir\n",
      "1492 Ġfilled\n",
      "1493 Ġagreed\n",
      "1494 Ġsomeone\n",
      "1495 Jack\n",
      "1496 Ġcontinued\n",
      "1497 room\n",
      "1498 Ġcreat\n",
      "1499 asure\n",
      "1500 'll\n",
      "1501 Ġcount\n",
      "1502 Ġwants\n",
      "1503 Ġsquirrel\n",
      "1504 ĠEm\n",
      "1505 Ġpink\n",
      "1506 Ġleaves\n",
      "1507 ask\n",
      "1508 Ġenough\n",
      "1509 ey\n",
      "1510 ĠThere\n",
      "1511 ĠTommy\n",
      "1512 Ġlion\n",
      "1513 From\n",
      "1514 ama\n",
      "1515 ee\n",
      "1516 OK\n",
      "1517 Ġmorning\n",
      "1518 Ġvis\n",
      "1519 Ġmoment\n",
      "1520 Ġfinally\n",
      "1521 Ġgetting\n",
      "1522 Ġstayed\n",
      "1523 Ġcookies\n",
      "1524 Ġbreak\n",
      "1525 app\n",
      "1526 Ġpoin\n",
      "1527 ance\n",
      "1528 Ġbeach\n",
      "1529 ĠK\n",
      "1530 Ġfew\n",
      "1531 ĠMaybe\n",
      "1532 Ġscary\n",
      "1533 Ġfight\n",
      "1534 Ġsometimes\n",
      "1535 row\n",
      "1536 ash\n",
      "1537 ries\n",
      "1538 ced\n",
      "1539 red\n",
      "1540 Ġturned\n",
      "1541 Ġhungry\n",
      "1542 Ġfall\n",
      "1543 Ġdinner\n",
      "1544 gon\n",
      "1545 Ġmother\n",
      "1546 Ġgrandma\n",
      "1547 Ġju\n",
      "1548 Ġwet\n",
      "1549 ĠWhat\n",
      "1550 Ġamazing\n",
      "1551 apped\n",
      "1552 Ġtrying\n",
      "1553 His\n",
      "1554 Ġcream\n",
      "1555 Ġdaddy\n",
      "1556 Ġperfect\n",
      "1557 Ġpi\n",
      "1558 Ġmakes\n",
      "1559 Ġcastle\n",
      "1560 Ġothers\n",
      "1561 At\n",
      "1562 Ġclimbed\n",
      "1563 key\n",
      "1564 oup\n",
      "1565 ĠThis\n",
      "1566 This\n",
      "1567 Ġpictures\n",
      "1568 icy\n",
      "1569 Ġcomp\n",
      "1570 amp\n",
      "1571 Ġtalk\n",
      "1572 Ġmet\n",
      "1573 Ġmus\n",
      "1574 Ġwhite\n",
      "1575 oom\n",
      "1576 Ġlistened\n",
      "1577 Ġsmiles\n",
      "1578 man\n",
      "1579 Ġfur\n",
      "1580 Ġballoon\n",
      "1581 Ġclot\n",
      "1582 oring\n",
      "1583 ĠGra\n",
      "1584 Ġalone\n",
      "1585 Ġclothes\n",
      "1586 Ġpol\n",
      "1587 ĠBilly\n",
      "1588 lc\n",
      "1589 Ġtail\n",
      "1590 Ġjoy\n",
      "1591 ated\n",
      "1592 rot\n",
      "1593 Oh\n",
      "1594 Ġpuppy\n",
      "1595 Ġspl\n",
      "1596 ence\n",
      "1597 Ġmar\n",
      "1598 Ġwasn\n",
      "1599 Ġbrought\n",
      "1600 Ġdeep\n",
      "1601 Ġeverything\n",
      "1602 Ġpet\n",
      "1603 Ġsear\n",
      "1604 Ġstrange\n",
      "1605 ister\n",
      "1606 ctor\n",
      "1607 Ġspark\n",
      "1608 der\n",
      "1609 Ġsit\n",
      "1610 Ġwoods\n",
      "1611 Ġgrow\n",
      "1612 Ġpulled\n",
      "1613 ling\n",
      "1614 Ġsail\n",
      "1615 ĠTo\n",
      "1616 ott\n",
      "1617 Ġwon\n",
      "1618 Ġplan\n",
      "1619 Ġride\n",
      "1620 eter\n",
      "1621 Ġasks\n",
      "1622 Ġfox\n",
      "1623 Ġpie\n",
      "1624 Ġdanger\n",
      "1625 Ġtreat\n",
      "1626 uffy\n",
      "1627 Ġroll\n",
      "1628 Ġvisit\n",
      "1629 ĠAmy\n",
      "1630 os\n",
      "1631 Ġleave\n",
      "1632 med\n",
      "1633 ĠJen\n",
      "1634 Ġpat\n",
      "1635 ucky\n",
      "1636 Ġmusic\n",
      "1637 Ġamazed\n",
      "1638 Ġwaited\n",
      "1639 Ġteddy\n",
      "1640 Ġhide\n",
      "1641 me\n",
      "1642 ang\n",
      "1643 ever\n",
      "1644 Ġtowards\n",
      "1645 Max\n",
      "1646 ower\n",
      "1647 Ġfield\n",
      "1648 Ġland\n",
      "1649 Ġpre\n",
      "1650 Ġflying\n",
      "1651 zz\n",
      "1652 Ġpen\n",
      "1653 Ġsilly\n",
      "1654 Ġshared\n",
      "1655 Ġruns\n",
      "1656 ained\n",
      "1657 Ġowner\n",
      "1658 Ġcloud\n",
      "1659 ape\n",
      "1660 Ġliving\n",
      "1661 ugg\n",
      "1662 Ġqui\n",
      "1663 ames\n",
      "1664 Ġjob\n",
      "1665 Ġpromised\n",
      "1666 Okay\n",
      "1667 Ġbelie\n",
      "1668 igg\n",
      "1669 Ġmoral\n",
      "1670 Ġgu\n",
      "1671 Ġside\n",
      "1672 gs\n",
      "1673 orm\n",
      "1674 Ġlake\n",
      "1675 ol\n",
      "1676 Ġpa\n",
      "1677 Ġthinks\n",
      "1678 Maybe\n",
      "1679 cket\n",
      "1680 ope\n",
      "1681 Ġpaint\n",
      "1682 Ġsec\n",
      "1683 thy\n",
      "1684 Ġsister\n",
      "1685 ually\n",
      "1686 Ġparty\n",
      "1687 Ġquiet\n",
      "1688 ises\n",
      "1689 Ġmust\n",
      "1690 cle\n",
      "1691 Ġrace\n",
      "1692 ĠJim\n",
      "1693 avy\n",
      "1694 Ġmoney\n",
      "1695 Ġwear\n",
      "1696 sw\n",
      "1697 Ġworried\n",
      "1698 ased\n",
      "1699 up\n",
      "1700 Ġansw\n",
      "1701 unch\n",
      "1702 Ġslowly\n",
      "1703 Ġpot\n",
      "1704 eces\n",
      "1705 Ġcolorful\n",
      "1706 Ġfaster\n",
      "1707 Ġgrate\n",
      "1708 Ġow\n",
      "1709 Ġdance\n",
      "1710 Ġpieces\n",
      "1711 Ġbran\n",
      "1712 Ġbott\n",
      "1713 Ġwelc\n",
      "1714 Ġbroke\n",
      "1715 Ġcup\n",
      "1716 ix\n",
      "1717 Ġgrateful\n",
      "1718 Ġgif\n",
      "1719 Ġsuch\n",
      "1720 Ġbigger\n",
      "1721 ze\n",
      "1722 Ġtrain\n",
      "1723 ph\n",
      "1724 fort\n",
      "1725 Ġsnack\n",
      "1726 Ġcho\n",
      "1727 Ġreach\n",
      "1728 Ġblank\n",
      "1729 ĠAll\n",
      "1730 Ġmonster\n",
      "1731 Ġpro\n",
      "1732 Ġplant\n",
      "1733 Ġjoin\n",
      "1734 Ġriver\n",
      "1735 Ġblack\n",
      "1736 less\n",
      "1737 Ġwin\n",
      "1738 Ġcandy\n",
      "1739 ire\n",
      "1740 Ġblanket\n",
      "1741 Ġscream\n",
      "1742 Ġtreasure\n",
      "1743 Ġmagical\n",
      "1744 ear\n",
      "1745 Ġve\n",
      "1746 Ġprincess\n",
      "1747 Ġele\n",
      "1748 Ġsmart\n",
      "1749 Ġbike\n",
      "1750 Ġdangerous\n",
      "1751 Ġsign\n",
      "1752 Ġdragon\n",
      "1753 Ġacross\n",
      "1754 Ġmonkey\n",
      "1755 Sure\n",
      "1756 Ġbar\n",
      "1757 Ġeverywhere\n",
      "1758 Ġmost\n",
      "1759 ĠDaddy\n",
      "1760 Ġhelping\n",
      "1761 Ġnap\n",
      "1762 Ġfarmer\n",
      "1763 outh\n",
      "1764 Ġem\n",
      "1765 Ġmouth\n",
      "1766 Why\n",
      "1767 set\n",
      "1768 Ġdisapp\n",
      "1769 Ġwords\n",
      "1770 Ġje\n",
      "1771 ipped\n",
      "1772 Ġstre\n",
      "1773 ored\n",
      "1774 Hi\n",
      "1775 Ġtower\n",
      "1776 ming\n",
      "1777 eared\n",
      "1778 Ġthrew\n",
      "1779 Ġstepped\n",
      "1780 Ġheavy\n",
      "1781 Ġdolls\n",
      "1782 Ġpass\n",
      "1783 Ġbite\n",
      "1784 de\n",
      "1785 Ġbowl\n",
      "1786 Ġdirty\n",
      "1787 Ġtwins\n",
      "1788 Ġsame\n",
      "1789 Ġcrying\n",
      "1790 Ġbee\n",
      "1791 Ġspr\n",
      "1792 ere\n",
      "1793 Ġdoctor\n",
      "1794 ident\n",
      "1795 ĠMolly\n",
      "1796 Ġacc\n",
      "1797 Ġbelieve\n",
      "1798 Ġwouldn\n",
      "1799 Ġbath\n",
      "1800 Ġheal\n",
      "1801 ĠFl\n",
      "1802 chool\n",
      "1803 Ġhig\n",
      "1804 bble\n",
      "1805 Ġclosed\n",
      "1806 Ġcarrot\n",
      "1807 Ġheart\n",
      "1808 Mia\n",
      "1809 Ġstuck\n",
      "1810 cked\n",
      "1811 Ġcour\n",
      "1812 Ġfruit\n",
      "1813 Ġbuck\n",
      "1814 Ġmin\n",
      "1815 Ġatt\n",
      "1816 Ġteac\n",
      "1817 Ġschool\n",
      "1818 ĠMr\n",
      "1819 Ġbrown\n",
      "1820 Ġhoped\n",
      "1821 ĠJill\n",
      "1822 asket\n",
      "1823 iting\n",
      "1824 Ġsuddenly\n",
      "1825 Ġbasket\n",
      "1826 Ġfeels\n",
      "1827 Ġmix\n",
      "1828 Ġchair\n",
      "1829 Ġeating\n",
      "1830 Ġtown\n",
      "1831 Ġcourse\n",
      "1832 Ġcray\n",
      "1833 Ġclapped\n",
      "1834 Ġcoll\n",
      "1835 Ġgentle\n",
      "1836 Ġfairy\n",
      "1837 pping\n",
      "1838 Ġbutt\n",
      "1839 Ġpack\n",
      "1840 ventually\n",
      "1841 Ġstand\n",
      "1842 ier\n",
      "1843 Ġdrove\n",
      "1844 ors\n",
      "1845 Ġpushed\n",
      "1846 br\n",
      "1847 issed\n",
      "1848 Ġwelcome\n",
      "1849 ts\n",
      "1850 Ġswings\n",
      "1851 Ġwithout\n",
      "1852 Ġhigher\n",
      "1853 Ġtoday\n",
      "1854 Ġneigh\n",
      "1855 Ġpocket\n",
      "1856 orrow\n",
      "1857 Ġhit\n",
      "1858 Ġteacher\n",
      "1859 Ġneighb\n",
      "1860 Ġpers\n",
      "1861 ord\n",
      "1862 Ġsmo\n",
      "1863 Ġgames\n",
      "1864 ourn\n",
      "1865 Ġpiece\n",
      "1866 ract\n",
      "1867 Ġcheered\n",
      "1868 Ġwings\n",
      "1869 Ġforget\n",
      "1870 Ġben\n",
      "1871 Ġexplained\n",
      "1872 Ġjourn\n",
      "1873 Ġyard\n",
      "1874 Ġlonger\n",
      "1875 Ġfree\n",
      "1876 Finally\n",
      "1877 ible\n",
      "1878 Ġcorn\n",
      "1879 Ġaccident\n",
      "1880 ho\n",
      "1881 ead\n",
      "1882 Ġdry\n",
      "1883 Ġalong\n",
      "1884 umb\n",
      "1885 ĠMary\n",
      "1886 ment\n",
      "1887 cy\n",
      "1888 Ġnoises\n",
      "1889 itting\n",
      "1890 Ġneck\n",
      "1891 Ġsang\n",
      "1892 Ġinst\n",
      "1893 Ġlate\n",
      "1894 Ġhappen\n",
      "1895 Ġthrow\n",
      "1896 Ġhugs\n",
      "1897 Lila\n",
      "1898 Ġyoung\n",
      "1899 Ġturns\n",
      "1900 Ġstories\n",
      "1901 vel\n",
      "1902 Ġshoes\n",
      "1903 phant\n",
      "1904 Ġlon\n",
      "1905 Ġmiss\n",
      "1906 Ġadventures\n",
      "1907 Ġsinging\n",
      "1908 Ġtrou\n",
      "1909 Ġwell\n",
      "1910 Ġsea\n",
      "1911 Ġlunch\n",
      "1912 Ġapple\n",
      "1913 Ġupset\n",
      "1914 Ġlonely\n",
      "1915 Ġkey\n",
      "1916 ches\n",
      "1917 Ġbelong\n",
      "1918 bby\n",
      "1919 oun\n",
      "1920 Ġdist\n",
      "1921 Ġsecret\n",
      "1922 Ġstreet\n",
      "1923 Ġplac\n",
      "1924 Ġelephant\n",
      "1925 Ġtom\n",
      "1926 Ġwish\n",
      "1927 Ġfence\n",
      "1928 Ġmine\n",
      "1929 ountain\n",
      "1930 Ġmat\n",
      "1931 ek\n",
      "1932 Ġshap\n",
      "1933 Ġshook\n",
      "1934 Ġexploring\n",
      "1935 Ġmoved\n",
      "1936 Ġpurp\n",
      "1937 Ġyear\n",
      "1938 aughty\n",
      "1939 Ġnearby\n",
      "1940 Ġnaughty\n",
      "1941 Ġstar\n",
      "1942 Ġsoup\n",
      "1943 Ġshop\n",
      "1944 Ġwise\n",
      "1945 ĠGrandma\n",
      "1946 Ġstars\n",
      "1947 Ġowl\n",
      "1948 Ġbring\n",
      "1949 fused\n",
      "1950 Ġjar\n",
      "1951 bow\n",
      "1952 Do\n",
      "1953 ocked\n",
      "1954 Ġinv\n",
      "1955 Ġexp\n",
      "1956 Ġwhe\n",
      "1957 yard\n",
      "1958 Ġcaught\n",
      "1959 Ġsu\n",
      "1960 ward\n",
      "1961 Ġbackyard\n",
      "1962 Ġseemed\n",
      "1963 ail\n",
      "1964 Ġes\n",
      "1965 Ġrelie\n",
      "1966 Ġdropped\n",
      "1967 Ġph\n",
      "1968 Ġrocks\n",
      "1969 ĠEmma\n",
      "1970 aughter\n",
      "1971 llo\n",
      "1972 Ġ3\n",
      "1973 ush\n",
      "1974 Ġdrink\n",
      "1975 Ġbucket\n",
      "1976 Ġdes\n",
      "1977 Ġca\n",
      "1978 adow\n",
      "1979 ces\n",
      "1980 Ġpurple\n",
      "1981 Ġswam\n",
      "1982 Ġfarm\n",
      "1983 Ġresp\n",
      "1984 Ġtaking\n",
      "1985 Ġmail\n",
      "1986 Ġorange\n",
      "1987 Ġthough\n",
      "1988 ions\n",
      "1989 And\n",
      "1990 Ġshapes\n",
      "1991 Ġpast\n",
      "1992 col\n",
      "1993 Ġcow\n",
      "1994 Ġstu\n",
      "1995 ĠThank\n",
      "1996 Ġwoke\n",
      "1997 Ġbench\n",
      "1998 Ġsounds\n",
      "1999 Ġaf\n",
      "2000 ung\n",
      "2001 ity\n",
      "2002 sy\n",
      "2003 Ġwondered\n",
      "2004 Ġbusy\n",
      "2005 Ġfit\n",
      "2006 Ġtiny\n",
      "2007 Ġob\n",
      "2008 Ġnose\n",
      "2009 Ġsitting\n",
      "2010 Ġnest\n",
      "2011 Ġrainbow\n",
      "2012 ese\n",
      "2013 Ġdaughter\n",
      "2014 Ġtakes\n",
      "2015 Ġmark\n",
      "2016 Ġmad\n",
      "2017 fish\n",
      "2018 Ġcou\n",
      "2019 Ġkite\n",
      "2020 to\n",
      "2021 ĠO\n",
      "2022 read\n",
      "2023 Ġholding\n",
      "2024 weet\n",
      "2025 Ġnothing\n",
      "2026 Ġcomes\n",
      "2027 Ġjuice\n",
      "2028 Ġarms\n",
      "2029 thday\n",
      "2030 Ġpig\n",
      "2031 Ġcoat\n",
      "2032 og\n",
      "2033 ĠFluffy\n",
      "2034 ining\n",
      "2035 Ġcir\n",
      "2036 ĠInside\n",
      "2037 Ġbranch\n",
      "2038 raid\n",
      "2039 Ġrelieved\n",
      "2040 pper\n",
      "2041 Ġafraid\n",
      "2042 cing\n",
      "2043 ose\n",
      "2044 idge\n",
      "2045 Ġdriver\n",
      "2046 Ġmil\n",
      "2047 Ġforever\n"
     ]
    }
   ],
   "source": [
    "for n, i in sorted([(k, v) for v, k in tokenizer.vocab.items()]):\n",
    "    print(n, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): GPTNeoForCausalLM(\n",
       "    (transformer): GPTNeoModel(\n",
       "      (wte): Embedding(2048, 64)\n",
       "      (wpe): Embedding(1024, 64)\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-7): 8 x GPTNeoBlock(\n",
       "          (ln_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPTNeoAttention(\n",
       "            (attention): GPTNeoFlashAttention2(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (k_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "              (v_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "              (q_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "              (out_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (ln_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPTNeoMLP(\n",
       "            (c_fc): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (c_proj): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=64, out_features=2048, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.compile(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad) - model.lm_head.weight.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenize(e):\n",
    "    out = tokenizer(e['text'], truncation=True, return_attention_mask=False)\n",
    "    out['input_ids'].append(tokenizer.eos_token_id)\n",
    "    return out \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tok_train = train_data.map(tokenize, remove_columns=['text'], num_proc=8)\n",
    "# tok_val  = val_data.select(range(1000)).map(tokenize, remove_columns=['text'], num_proc=8)\n",
    "\n",
    "# tok_train = filtered_train_data.map(tokenize, remove_columns=['text'], num_proc=8)\n",
    "# tok_val  = val_data.select(range(1000)).map(tokenize, remove_columns=['text'], num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqPackIter:\n",
    "    def __init__(self, ds):\n",
    "        self.ds = [[i] for i in tqdm(ds)]\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return iter(self.ds)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_iter = SeqPackIter(tok_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_obj = iter(seq_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_packer = GreedyBestFitSequencePacker.from_composer(\n",
    "#     src_iterable = seq_iter,\n",
    "#     micro_batch_size=1,\n",
    "#     batch_size=1,\n",
    "#     max_seq_len=1024,\n",
    "#     pad_token_id=0,\n",
    "#     mask_token_id=0,\n",
    "#     ignore_token_id=0,\n",
    "#     mask_prob=0.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter_seq_pack = iter(sequence_packer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter_seq_pack)['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Reset the iterator\n",
    "# iter_seq_pack = iter(sequence_packer)\n",
    "\n",
    "# # Collect context lengths\n",
    "# context_lengths = [len(i['input_ids']) for i in tqdm(tok_train)]\n",
    "# # context_lengths = []\n",
    "# plt.show()\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(context_lengths, bins=50)\n",
    "# plt.title('Distribution of Context Lengths')\n",
    "# plt.xlabel('Context Length')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Ġadventures',\n",
       "  'Ġeverything',\n",
       "  'Ġremembered',\n",
       "  'Ġeverywhere',\n",
       "  'Ġunderstand',\n",
       "  '<|endoftext|>'],\n",
       " 10,\n",
       " [1906, 1601, 1405, 1757, 1454, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 10\n",
    "max_pos = []\n",
    "max_token = []\n",
    "for k, v in tokenizer.vocab.items():\n",
    "    if len(k) > max_len:\n",
    "        max_pos.append(v)\n",
    "        max_token.append(k)\n",
    "\n",
    "max_token, max_len, max_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./datasets/tinystories/packed/2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streaming import MDSWriter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "out_root = f'./datasets/tinystories/packed/{tokenizer.vocab_size}/'\n",
    "out_train = out_root + 'train/'\n",
    "out_val = out_root + 'val/'\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'ndarray:int32',\n",
    "    # 'attention_mask': 'ndarray:int64',\n",
    "}\n",
    "# with MDSWriter(out=out_train, columns=columns, compression='zstd') as writer:\n",
    "#     for sample in tqdm(sequence_packer):\n",
    "#         sample['input_ids'] = sample['input_ids'].squeeze().numpy().astype(np.int32)\n",
    "#         writer.write(sample)\n",
    "        \n",
    "# print('done with train')\n",
    "# with MDSWriter(out=out_val, columns=columns, compression='zstd') as writer:\n",
    "#     for sample in tok_val:\n",
    "#         sample['input_ids'] = sample['input_ids'].astype(np.int32)\n",
    "#         writer.write(sample)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streaming import StreamingDataset\n",
    "bs = 64\n",
    "tok_train = StreamingDataset(local=out_train, shuffle=True, shuffle_seed=42, batch_size=bs)\n",
    "tok_val = StreamingDataset(local=out_val, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564263"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_train[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([torch.tensor(e['input_ids']).to('cuda').to(torch.int64) for e in batch])\n",
    "    # masks = torch.stack([torch.tensor(e['attention_mask']).to('cuda') for e in batch])\n",
    "    labels = torch.stack([torch.tensor(e['input_ids']).to('cuda').to(torch.int64) for e in batch])\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        # 'attention_mask': masks,\n",
    "        'labels': labels,\n",
    "        # 'inputs_embeds': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = collate_fn\n",
    "\n",
    "torch.random.manual_seed(42)\n",
    "dl_train = DataLoader(tok_train[:-bs*2], batch_size=bs, collate_fn=collate_fn)\n",
    "dl_val = DataLoader(tok_train[-bs * 2:], batch_size=bs, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8815, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_train), len(dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1024])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl_train))['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(HuggingFaceModel):\n",
    "    def __init__(self, model, tokenizer, metrics=[], use_logits=False):\n",
    "        super().__init__(model, tokenizer, metrics=metrics, use_logits=use_logits)\n",
    "            \n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(**batch)\n",
    "    \n",
    "    def loss(self, outputs, batch):\n",
    "        return outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(tok_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tom',\n",
       " ' and',\n",
       " ' Mia',\n",
       " ' like',\n",
       " ' to',\n",
       " ' play',\n",
       " ' on',\n",
       " ' the',\n",
       " ' beach',\n",
       " '.',\n",
       " ' They',\n",
       " ' like',\n",
       " ' to',\n",
       " ' build',\n",
       " ' sand',\n",
       " ' cast',\n",
       " 'les',\n",
       " ' and',\n",
       " ' s',\n",
       " 'ur',\n",
       " 'f',\n",
       " ' on',\n",
       " ' the',\n",
       " ' wa',\n",
       " 'ves',\n",
       " '.',\n",
       " ' They',\n",
       " ' have',\n",
       " ' a',\n",
       " ' big',\n",
       " ' bucket',\n",
       " ' and',\n",
       " ' a',\n",
       " ' small',\n",
       " ' sho',\n",
       " 'vel',\n",
       " ' to',\n",
       " ' make',\n",
       " ' their',\n",
       " ' cast',\n",
       " 'les',\n",
       " '.',\n",
       " ' They',\n",
       " ' have',\n",
       " ' a',\n",
       " ' blue',\n",
       " ' s',\n",
       " 'ur',\n",
       " 'f',\n",
       " ' bo',\n",
       " 'ard',\n",
       " ' to',\n",
       " ' ride',\n",
       " ' on',\n",
       " ' the',\n",
       " ' water',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'One',\n",
       " ' day',\n",
       " ',',\n",
       " ' they',\n",
       " ' go',\n",
       " ' to',\n",
       " ' the',\n",
       " ' beach',\n",
       " ' with',\n",
       " ' their',\n",
       " ' mom',\n",
       " ' and',\n",
       " ' dad',\n",
       " '.',\n",
       " ' They',\n",
       " ' find',\n",
       " ' a',\n",
       " ' good',\n",
       " ' spot',\n",
       " ' to',\n",
       " ' build',\n",
       " ' their',\n",
       " ' sand',\n",
       " ' castle',\n",
       " '.',\n",
       " ' They',\n",
       " ' d',\n",
       " 'ig',\n",
       " ' and',\n",
       " ' p',\n",
       " 'ile',\n",
       " ' and',\n",
       " ' pat',\n",
       " ' the',\n",
       " ' sand',\n",
       " '.',\n",
       " ' They',\n",
       " ' make',\n",
       " ' a',\n",
       " ' big',\n",
       " ' tower',\n",
       " ' and',\n",
       " ' a',\n",
       " ' small',\n",
       " ' door',\n",
       " '.',\n",
       " ' They',\n",
       " ' put',\n",
       " ' she',\n",
       " 'll',\n",
       " 's',\n",
       " ' and',\n",
       " ' st',\n",
       " 'on',\n",
       " 'es',\n",
       " ' to',\n",
       " ' dec',\n",
       " 'or',\n",
       " 'ate',\n",
       " ' their',\n",
       " ' castle',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\"',\n",
       " 'Look',\n",
       " ' at',\n",
       " ' our',\n",
       " ' castle',\n",
       " ',',\n",
       " ' mom',\n",
       " ' and',\n",
       " ' dad',\n",
       " '!\"',\n",
       " ' Tom',\n",
       " ' says',\n",
       " '.',\n",
       " ' \"',\n",
       " 'It',\n",
       " ' is',\n",
       " ' very',\n",
       " ' big',\n",
       " ' and',\n",
       " ' pretty',\n",
       " '!\"',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\"',\n",
       " 'It',\n",
       " ' is',\n",
       " ',',\n",
       " ' Tom',\n",
       " '.',\n",
       " ' You',\n",
       " ' and',\n",
       " ' Mia',\n",
       " ' did',\n",
       " ' a',\n",
       " ' great',\n",
       " ' job',\n",
       " '!\"',\n",
       " ' Mom',\n",
       " ' says',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\"',\n",
       " 'Can',\n",
       " ' we',\n",
       " ' go',\n",
       " ' s',\n",
       " 'ur',\n",
       " 'f',\n",
       " ' now',\n",
       " '?\"',\n",
       " ' Mia',\n",
       " ' asks',\n",
       " '.',\n",
       " ' \"',\n",
       " 'The',\n",
       " ' wa',\n",
       " 'ves',\n",
       " ' look',\n",
       " ' fun',\n",
       " '!\"',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\"',\n",
       " 'Sure',\n",
       " ',',\n",
       " ' Mia',\n",
       " '.',\n",
       " ' But',\n",
       " ' you',\n",
       " ' have',\n",
       " ' to',\n",
       " ' be',\n",
       " ' careful',\n",
       " '.',\n",
       " ' The',\n",
       " ' water',\n",
       " ' can',\n",
       " ' be',\n",
       " ' dangerous',\n",
       " '.',\n",
       " ' You',\n",
       " ' have',\n",
       " ' to',\n",
       " ' stay',\n",
       " ' close',\n",
       " ' to',\n",
       " ' us',\n",
       " ' and',\n",
       " ' wear',\n",
       " ' your',\n",
       " ' li',\n",
       " 'fe',\n",
       " ' j',\n",
       " 'ack',\n",
       " 'et',\n",
       " 's',\n",
       " '.',\n",
       " ' They',\n",
       " ' will',\n",
       " ' keep',\n",
       " ' you',\n",
       " ' safe',\n",
       " ' and',\n",
       " ' flo',\n",
       " 'at',\n",
       " 'y',\n",
       " '.\"',\n",
       " ' Dad',\n",
       " ' says',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\"',\n",
       " 'Okay',\n",
       " ',',\n",
       " ' dad',\n",
       " '.',\n",
       " ' We',\n",
       " ' will',\n",
       " ' be',\n",
       " ' safe',\n",
       " ' and',\n",
       " ' flo',\n",
       " 'at',\n",
       " 'y',\n",
       " '.\"',\n",
       " ' Mia',\n",
       " ' says',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Tom',\n",
       " ' and',\n",
       " ' Mia',\n",
       " ' put',\n",
       " ' on',\n",
       " ' their',\n",
       " ' li',\n",
       " 'fe',\n",
       " ' j',\n",
       " 'ack',\n",
       " 'et',\n",
       " 's',\n",
       " ' and',\n",
       " ' gra',\n",
       " 'b',\n",
       " ' their',\n",
       " ' s',\n",
       " 'ur',\n",
       " 'f',\n",
       " ' bo',\n",
       " 'ard',\n",
       " '.',\n",
       " ' They',\n",
       " ' run',\n",
       " ' to',\n",
       " ' the',\n",
       " ' water',\n",
       " ' and',\n",
       " ' jump',\n",
       " ' on',\n",
       " ' their',\n",
       " ' bo',\n",
       " 'ard',\n",
       " '.',\n",
       " ' They',\n",
       " ' p',\n",
       " 'ad',\n",
       " 'd',\n",
       " 'le',\n",
       " ' and',\n",
       " ' wait',\n",
       " ' for',\n",
       " ' a',\n",
       " ' good',\n",
       " ' wa',\n",
       " 've',\n",
       " '.',\n",
       " ' They',\n",
       " ' see',\n",
       " ' a',\n",
       " ' big',\n",
       " ' one',\n",
       " ' coming',\n",
       " '.',\n",
       " ' They',\n",
       " ' stand',\n",
       " ' up',\n",
       " ' and',\n",
       " ' s',\n",
       " 'ur',\n",
       " 'f',\n",
       " ' on',\n",
       " ' the',\n",
       " ' wa',\n",
       " 've',\n",
       " '.',\n",
       " ' They',\n",
       " ' feel',\n",
       " ' the',\n",
       " ' wind',\n",
       " ' and',\n",
       " ' the',\n",
       " ' spr',\n",
       " 'ay',\n",
       " '.',\n",
       " ' They',\n",
       " ' smile',\n",
       " ' and',\n",
       " ' laugh',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\"',\n",
       " 'Wow',\n",
       " ',',\n",
       " ' this',\n",
       " ' is',\n",
       " ' so',\n",
       " ' fun',\n",
       " '!\"',\n",
       " ' Tom',\n",
       " ' says',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\"',\n",
       " 'I',\n",
       " ' love',\n",
       " ' s',\n",
       " 'ur',\n",
       " 'f',\n",
       " 'ing',\n",
       " '!\"',\n",
       " ' Mia',\n",
       " ' says',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'They',\n",
       " ' s',\n",
       " 'ur',\n",
       " 'f',\n",
       " ' until',\n",
       " ' they',\n",
       " ' are',\n",
       " ' tired',\n",
       " '.',\n",
       " ' Then',\n",
       " ' they',\n",
       " ' go',\n",
       " ' back',\n",
       " ' to',\n",
       " ' their',\n",
       " ' sand',\n",
       " ' castle',\n",
       " '.',\n",
       " ' They',\n",
       " ' are',\n",
       " ' happy',\n",
       " ' and',\n",
       " ' proud',\n",
       " ' of',\n",
       " ' their',\n",
       " ' day',\n",
       " ' on',\n",
       " ' the',\n",
       " ' beach',\n",
       " '.',\n",
       " ' They',\n",
       " ' hug',\n",
       " ' their',\n",
       " ' mom',\n",
       " ' and',\n",
       " ' dad',\n",
       " ' and',\n",
       " ' thank',\n",
       " ' them',\n",
       " ' for',\n",
       " ' taking',\n",
       " ' them',\n",
       " '.',\n",
       " ' They',\n",
       " ' say',\n",
       " ' goodbye',\n",
       " ' to',\n",
       " ' their',\n",
       " ' castle',\n",
       " ' and',\n",
       " ' their',\n",
       " ' s',\n",
       " 'ur',\n",
       " 'f',\n",
       " ' bo',\n",
       " 'ard',\n",
       " '.',\n",
       " ' They',\n",
       " ' prom',\n",
       " 'ise',\n",
       " ' to',\n",
       " ' come',\n",
       " ' back',\n",
       " ' soon',\n",
       " '.',\n",
       " '<|endoftext|>',\n",
       " 'Anna',\n",
       " ' liked',\n",
       " ' to',\n",
       " ' cre',\n",
       " 'ate',\n",
       " ' things',\n",
       " ' with',\n",
       " ' her',\n",
       " ' toys',\n",
       " '.',\n",
       " ' She',\n",
       " ' had',\n",
       " ' many',\n",
       " ' toys',\n",
       " ',',\n",
       " ' but',\n",
       " ' her',\n",
       " ' favorite',\n",
       " ' was',\n",
       " ' a',\n",
       " ' ha',\n",
       " 'n',\n",
       " 'ger',\n",
       " '.',\n",
       " ' She',\n",
       " ' could',\n",
       " ' be',\n",
       " 'nd',\n",
       " ' it',\n",
       " ' and',\n",
       " ' tw',\n",
       " 'ist',\n",
       " ' it',\n",
       " ' and',\n",
       " ' make',\n",
       " ' it',\n",
       " ' into',\n",
       " ' different',\n",
       " ' shapes',\n",
       " '.',\n",
       " ' She',\n",
       " ' made',\n",
       " ' a',\n",
       " ' cir',\n",
       " 'cle',\n",
       " ',',\n",
       " ' a',\n",
       " ' tri',\n",
       " 'ang',\n",
       " 'le',\n",
       " ',',\n",
       " ' a',\n",
       " ' star',\n",
       " ',',\n",
       " ' and',\n",
       " ' a',\n",
       " ' heart',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'One',\n",
       " ' day',\n",
       " ',',\n",
       " ' she',\n",
       " ' wanted',\n",
       " ' to',\n",
       " ' show',\n",
       " ' her',\n",
       " ' mom',\n",
       " ' what',\n",
       " ' she',\n",
       " ' creat',\n",
       " 'ed',\n",
       " '.',\n",
       " ' She',\n",
       " ' ran',\n",
       " ' to',\n",
       " ' the',\n",
       " ' kitchen',\n",
       " ',',\n",
       " ' where',\n",
       " ' her',\n",
       " ' mom',\n",
       " ' was',\n",
       " ' c',\n",
       " 'oo',\n",
       " 'king',\n",
       " '.',\n",
       " ' She',\n",
       " ' held',\n",
       " ' up',\n",
       " ' her',\n",
       " ' ha',\n",
       " 'n',\n",
       " 'ger',\n",
       " ' heart',\n",
       " ' and',\n",
       " ' said',\n",
       " ',',\n",
       " ' \"',\n",
       " 'Look',\n",
       " ',',\n",
       " ' mom',\n",
       " ',',\n",
       " ' I',\n",
       " ' made',\n",
       " ' this',\n",
       " ' for',\n",
       " ' you',\n",
       " '!\"',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Her',\n",
       " ' mom',\n",
       " ' smiled',\n",
       " ' and',\n",
       " ' hugged',\n",
       " ' her',\n",
       " '.',\n",
       " ' She',\n",
       " ' said',\n",
       " ',',\n",
       " ' \"',\n",
       " 'Thank',\n",
       " ' you',\n",
       " ',',\n",
       " ' Anna',\n",
       " ',',\n",
       " ' this',\n",
       " ' is',\n",
       " ' very',\n",
       " ' beautiful',\n",
       " '.',\n",
       " ' You',\n",
       " ' are',\n",
       " ' very',\n",
       " ' creat',\n",
       " 'ive',\n",
       " ' and',\n",
       " ' cle',\n",
       " 'ver',\n",
       " '.',\n",
       " ' I',\n",
       " ' love',\n",
       " ' you',\n",
       " ' and',\n",
       " ' your',\n",
       " ' ha',\n",
       " 'n',\n",
       " 'ger',\n",
       " ' heart',\n",
       " '.\"',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Anna',\n",
       " ' felt',\n",
       " ' happy',\n",
       " ' and',\n",
       " ' proud',\n",
       " '.',\n",
       " ' She',\n",
       " ' said',\n",
       " ',',\n",
       " ' \"',\n",
       " 'I',\n",
       " ' love',\n",
       " ' you',\n",
       " ' too',\n",
       " ',',\n",
       " ' mom',\n",
       " '.',\n",
       " ' Can',\n",
       " ' I',\n",
       " ' make',\n",
       " ' more',\n",
       " ' things',\n",
       " ' with',\n",
       " ' my',\n",
       " ' ha',\n",
       " 'n',\n",
       " 'ger',\n",
       " '?\"',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Her',\n",
       " ' mom',\n",
       " ' said',\n",
       " ',',\n",
       " ' \"',\n",
       " 'O',\n",
       " 'f',\n",
       " ' course',\n",
       " ',',\n",
       " ' you',\n",
       " ' can',\n",
       " '.',\n",
       " ' But',\n",
       " ' be',\n",
       " ' careful',\n",
       " ' not',\n",
       " ' to',\n",
       " ' hurt',\n",
       " ' your',\n",
       " 'self',\n",
       " ' or',\n",
       " ' break',\n",
       " ' anything',\n",
       " '.',\n",
       " ' And',\n",
       " ' don',\n",
       " \"'t\",\n",
       " ' forget',\n",
       " ' to',\n",
       " ' clean',\n",
       " ' up',\n",
       " ' when',\n",
       " ' you',\n",
       " ' are',\n",
       " ' done',\n",
       " '.\"',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Anna',\n",
       " ' nodded',\n",
       " ' and',\n",
       " ' ran',\n",
       " ' back',\n",
       " ' to',\n",
       " ' her',\n",
       " ' room',\n",
       " '.',\n",
       " ' She',\n",
       " ' had',\n",
       " ' many',\n",
       " ' ide',\n",
       " 'as',\n",
       " ' for',\n",
       " ' what',\n",
       " ' to',\n",
       " ' cre',\n",
       " 'ate',\n",
       " ' next',\n",
       " '.',\n",
       " ' She',\n",
       " ' was',\n",
       " ' having',\n",
       " ' fun',\n",
       " ' with',\n",
       " ' her',\n",
       " ' ha',\n",
       " 'n',\n",
       " 'ger',\n",
       " '.',\n",
       " '<|endoftext|>',\n",
       " 'Anna',\n",
       " ' and',\n",
       " ' Ben',\n",
       " ' are',\n",
       " ' twins',\n",
       " '.',\n",
       " ' They',\n",
       " ' like',\n",
       " ' to',\n",
       " ' play',\n",
       " ' in',\n",
       " ' their',\n",
       " ' room',\n",
       " '.',\n",
       " ' They',\n",
       " ' have',\n",
       " ' a',\n",
       " ' big',\n",
       " ' box',\n",
       " ' that',\n",
       " ' they',\n",
       " ' pretend',\n",
       " ' is',\n",
       " ' a',\n",
       " ' castle',\n",
       " '.',\n",
       " ' They',\n",
       " ' put',\n",
       " ' a',\n",
       " ' blanket',\n",
       " ' over',\n",
       " ' the',\n",
       " ' box',\n",
       " ' and',\n",
       " ' make',\n",
       " ' a',\n",
       " ' door',\n",
       " ' with',\n",
       " ' sc',\n",
       " 'iss',\n",
       " 'ors',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'One',\n",
       " ' night',\n",
       " ',',\n",
       " ' Anna',\n",
       " ' and',\n",
       " ' Ben',\n",
       " ' have',\n",
       " ' a',\n",
       " ' bad',\n",
       " ' dream',\n",
       " '.',\n",
       " ' They',\n",
       " ' dream',\n",
       " ' that',\n",
       " ' a',\n",
       " ' dragon',\n",
       " ' comes',\n",
       " ' to',\n",
       " ' their',\n",
       " ' castle',\n",
       " ' and',\n",
       " ' tri',\n",
       " 'es',\n",
       " ' to',\n",
       " ' b',\n",
       " 'urn',\n",
       " ' it',\n",
       " '.',\n",
       " ' They',\n",
       " ' are',\n",
       " ' very',\n",
       " ' scared',\n",
       " '.',\n",
       " ' They',\n",
       " ' wa',\n",
       " 'ke',\n",
       " ' up',\n",
       " ' and',\n",
       " ' cry',\n",
       " '.',\n",
       " ' They',\n",
       " ' want',\n",
       " ' their',\n",
       " ' mom',\n",
       " ' and',\n",
       " ' dad',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Mom',\n",
       " ' and',\n",
       " ' dad',\n",
       " ' hear',\n",
       " ' them',\n",
       " ' cry',\n",
       " '.',\n",
       " ' They',\n",
       " ' run',\n",
       " ' to',\n",
       " ' their',\n",
       " ' room',\n",
       " '.',\n",
       " ' They',\n",
       " ' see',\n",
       " ' the',\n",
       " ' box',\n",
       " ' and',\n",
       " ' the',\n",
       " ' blanket',\n",
       " '.',\n",
       " ' They',\n",
       " ' hug',\n",
       " ' Anna',\n",
       " ' and',\n",
       " ' Ben',\n",
       " ' and',\n",
       " ' tell',\n",
       " ' them',\n",
       " ' it',\n",
       " ' is',\n",
       " ' just',\n",
       " ' a',\n",
       " ' dream',\n",
       " '.',\n",
       " ' They',\n",
       " ' say',\n",
       " ' there',\n",
       " ' is',\n",
       " ' no',\n",
       " ' dragon',\n",
       " ' and',\n",
       " ' their',\n",
       " ' castle',\n",
       " ' is',\n",
       " ' safe',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'Anna',\n",
       " ' and',\n",
       " ' Ben',\n",
       " ' feel',\n",
       " ' better',\n",
       " '.',\n",
       " ' They',\n",
       " ' c',\n",
       " 'udd',\n",
       " 'le',\n",
       " ' with',\n",
       " ' mom',\n",
       " ' and',\n",
       " ' dad',\n",
       " ' in',\n",
       " ' their',\n",
       " ' bed',\n",
       " '.',\n",
       " ' They',\n",
       " ' hold',\n",
       " ' them',\n",
       " ' tight',\n",
       " '.',\n",
       " ' They',\n",
       " ' are',\n",
       " ' not',\n",
       " ' scared',\n",
       " ' anymore',\n",
       " '.',\n",
       " ' They',\n",
       " ' fall',\n",
       " ' as',\n",
       " 'leep',\n",
       " ' and',\n",
       " ' have',\n",
       " ' good',\n",
       " ' dream',\n",
       " 's',\n",
       " '.',\n",
       " ' They',\n",
       " ' dream',\n",
       " ' that',\n",
       " ' they',\n",
       " ' are',\n",
       " ' kn',\n",
       " 'ight',\n",
       " 's',\n",
       " ' and',\n",
       " ' princess',\n",
       " 'es',\n",
       " ' in',\n",
       " ' their',\n",
       " ' castle',\n",
       " '.',\n",
       " ' They',\n",
       " ' have',\n",
       " ' fun',\n",
       " ' and',\n",
       " ' laugh',\n",
       " '.',\n",
       " ' They',\n",
       " ' are',\n",
       " ' happy',\n",
       " '.',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " '<|endoftext|>',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from composer.models.huggingface import HuggingFaceModel\n",
    "from composer.metrics import CrossEntropy, MaskedAccuracy, LanguageCrossEntropy\n",
    "\n",
    "metrics = [MaskedAccuracy(ignore_index=0), LanguageCrossEntropy(ignore_index=0)]\n",
    "# Package as a trainer-friendly Composer model\n",
    "my_model = MyModel(model, tokenizer, metrics=metrics, use_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/composer/core/evaluator.py:147: UserWarning: Setting `device_eval_microbatch_size='auto'` is an experimental feature which may cause uncaught Cuda Out of Memory errors. In this case, please manually set device_eval_microbatch_size explicitly to an integer instead.\n",
      "  warnings.warn((\n"
     ]
    }
   ],
   "source": [
    "from composer import Evaluator\n",
    "eval_evaluator = Evaluator(\n",
    "    label='acc',\n",
    "    dataloader=dl_val,\n",
    "    metric_names=['LanguageCrossEntropy', 'MaskedAccuracy'],\n",
    "    device_eval_microbatch_size='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/composer/trainer/trainer.py:247: UserWarning: `device_train_microbatch_size='auto'` may potentially fail with unexpected CUDA errors. Auto microbatching attempts to catch CUDA Out of Memory errors and adjust the batch size, but it is possible CUDA will be put into an irrecoverable state due to PyTorch bugs, e.g. integer overflow. In this case, please manually set device_train_microbatch_size explicitly to an integer instead.\n",
      "  warnings.warn((\n"
     ]
    }
   ],
   "source": [
    "from composer.optim import DecoupledAdamW, CosineAnnealingWithWarmupScheduler\n",
    "from composer.loggers import InMemoryLogger, FileLogger\n",
    "from composer.metrics import MaskedAccuracy\n",
    "\n",
    "optim = DecoupledAdamW(my_model.parameters(), lr=2e-3, weight_decay=1e-7)\n",
    "lr_scheduler = CosineAnnealingWithWarmupScheduler(t_warmup='100ba', t_max=\"1dur\")\n",
    "\n",
    "logger = InMemoryLogger()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=my_model,\n",
    "    train_dataloader=dl_train, \n",
    "    eval_dataloader=eval_evaluator,\n",
    "    optimizers=optim,\n",
    "    schedulers=lr_scheduler,\n",
    "    max_duration=\"2ep\",\n",
    "    eval_interval='1ba',\n",
    "    save_folder=\"training/pretrain/33M/packed/\" + str(optim.param_groups[0]['lr']),\n",
    "    save_interval=\"2000ba\",\n",
    "    # save_filename=\"hf_model.pt\",\n",
    "    save_overwrite=True,\n",
    "    device_train_microbatch_size='auto',\n",
    "    loggers=logger,\n",
    "    device='gpu',\n",
    "    precision='amp_bf16',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Config:\n",
      "composer_commit_hash: None\n",
      "composer_version: 0.30.0\n",
      "node_name: unknown because NODENAME environment variable not set\n",
      "num_gpus_per_node: 1\n",
      "num_nodes: 1\n",
      "rank_zero_seed: 1622799068\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba51fc30d3b41dba59fce6958c701da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train          Epoch   0:    0%|| 0/8815 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 15:03:34.850000 5971 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cf9f21c6d94076805182997ea4ed0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   1:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37dcf1c239ea4f50b58900f5ff43919e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   2:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d089395b7c22464eb5d35d461214a852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   3:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8e80a66d6b48e1b8eaf157f4e7c7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   4:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84137a4e7dc647fe891c09590ea4f196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   5:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76412864b5774a9798c4f112d8345476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   6:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17236859dd1e4c61bc0ebe833ca2bb0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   7:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06cfb9b9d9fd43609a34d8c550542a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   8:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cce7fdfd85d43f4a6f10884158fcf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch   9:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4ac2e109ee45deb40db23dcba27e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  10:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5371939d9d45d5b1851f2faac57428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  11:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c3b114793f4ecd82af01de4a644e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  12:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab1698107c2473fa1ff3a2d12a699f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  13:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4987afef4c45cea918d06e0201c9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  14:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f65b18b9b134ad4a8de330ec5cd1ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  15:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f5414b86e64449aeab52680fcca8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  16:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf488e2c0929458fbcaf97f4ad3e792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  17:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161a588e07834b48a6ebc1e9d0eb1a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  18:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc4ca9363f749c7b008f6f8603d369c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  19:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e897a3d4394512988be5594bcced27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  20:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5366a407b7874d1fabe3aa2c1f2a8224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  21:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c654f6d8877140cba56bf3456793ad7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  22:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1bbfcc90f7e4203a7dd304651d866ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  23:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36d68e8b9454a9aa23e24da138a5f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  24:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5d85b343e94e62ad3b1a2bfab426b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  25:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce246a10da94ea2b38a4c02c40d5cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  26:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c8fba83a974e19a1ad0624fdf63e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  27:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2ee0402fed495e98e27f73977807d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  28:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ee26fbb5c44cd0838ef8ff5e5192f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  29:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310b1f85f57945a9950f075d5879e282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  30:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4a23a07fef46f8bafcd6152735a943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  31:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9ecde80e064ae9be8aef328e474a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  32:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dbe7a296904638bdf515d6f0f27a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  33:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3bb8ffdb5045719d4f8850e0dd3df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  34:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ac2e2805f240448c40d11c23cf1fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  35:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ad44ca781942e1928ce6c0756fe308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  36:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d225e34ca2944e42a05ffa75ac417ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  37:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afe105b02e9476f9cadfc576fe287a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  38:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc1c036f25a4276aec5a4debd055b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  39:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61beb60dbaa4de195c11d3805ae3569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  40:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4899c3cd79c40b3829bcd7d195816ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  41:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28695707e5064c078c13edc1d269e7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  42:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0875af19744a3d83dbc0aaec1999b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  43:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c963ecd683491dba757496bc2efdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  44:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f94ade20cd49ebaf46b042a35f62e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  45:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bb3bc96f914a72aac484778e972571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  46:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b471213ba21e444eadffe5d9cf990fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  47:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc9a24edbc44355892513cbc16e2bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  48:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d604c1c67fa347609d298e575c833db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  49:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20d3cb114414755b48b89b85f1cdf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  50:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bf99533e924ababf253d90a90ef5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  51:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90ca690fe4f4cbd984701ed8243a13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  52:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42a3f84ff0f4f3e9419ba0029a69878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  53:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76922f8b9254d229710c5396250fa4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  54:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14d4417b49fd418fbbc4cc7ef9a73b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  55:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e41467d99bf49f0bd02450a3549ae2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  56:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263a9120e4a24f3196ce6a65e31afe16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  57:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5914f97a815246d8ac1ebe83efcb5c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  58:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f371b73248b4adda8d287fce7341cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  59:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d1d6e034324f0f8f6034eb4e751cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  60:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ea0d47732046de93fe4322f1faefcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  61:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7679fcb61f4fe6a4813d867f22f5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  62:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43af714da69434a852c70b6e2474308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  63:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125a34c0006d42e5ac5a280961aa2e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  64:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e146223599e44a86bfc3714d84ebbeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  65:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ad8d3da8a24e9b97586b0d0c5560eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  66:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bea093dbbb84a1fa42c940de6ecdf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  67:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc65002cb59045fa8a70ad174d45f0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  68:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f15ba0a32c244d1853f82cf8d9290b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  69:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d454d3cff6fa4cf3b4826b93eb4ad5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  70:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10a307fe4574744afb9fbcc09988d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  71:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48496dc793a462484880f1b25d9453f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  72:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "465b1df241e84a618e6dfcaf7c4ccb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  73:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eddb77174b5486b8f0dba4c1088fe26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  74:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ff62eb515946a1884ae366368740de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  75:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57935ff254e84469bed42f8434260790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  76:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350be4f3bdf64da4b4b21e876f559a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  77:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93ff93247644242a31a5b06e2e13d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  78:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b2cc88eaf64a55881a7788212a400c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  79:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34bc5633e674fd691d71d3505aa1071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  80:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0116b0053e24115b379e10d3eab847e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  81:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61abd662ced84cd790d1ae5cb2cbbe17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  82:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137ce69905bf4e56b7c3598f764ad421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  83:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf0a04cda854311b603caf2d6fd654e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  84:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e5e2af9dd94a409d29bc99ab957145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  85:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b071dc2301624dd19f03eed63ef3220e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  86:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7262c37bfdc44239bfeedc054da2b872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  87:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20720c946d3b47bbb7c06ed61c9f00ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  88:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fdaa65c96a432d808d7257166fb3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  89:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3a9329c07c4bb3851431fbf9d4986f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  90:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e242829a213b41799f14a967687b62ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  91:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974f6daae2b64cfc9f7d6352e76767a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  92:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ced7a1c270412db92ee29b11597be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  93:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4809ba8a0f4598b6298a918066ca94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  94:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87b4f53fd964feea350de36b3ed5988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  95:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9fea7f6ea94e8ba90885aa8c082722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  96:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f7cd4b96c34b4b97ae398d02291e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  97:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59aa8a27ff6b4cc997778a41100d8be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  98:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238698e52c05472cbcea80079c17b04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch  99:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c80b782d6f3442c8dedab75a9291de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 100:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d621fa3c6a6146c881e9ece978a22192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 101:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a07fdc69294d889c80a649e4874142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 102:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09025ef6af14eaaad47c32fed6212a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 103:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abecd475881c469b88ae661845f3e976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 104:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9be880b4f64b0686a2ec94eb6f9419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 105:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdc3dac3cde45049e8f27eb7cc147d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 106:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcacb0023dc4b1097cc3150e0892c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 107:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f2062832844657bf986abc1bdb2a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 108:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec21896adcc54e0f8850367a0afbf051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 109:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1a8bb751bc45cb8dcd5e7473be9333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 110:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e44800133974c1fafb80e5d305f0b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 111:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9455da66c1a54a8786fa4e9911476929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 112:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4728dee24442b3b9e6d24beba8d7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 113:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4a2ea7fd6b48188224a73dfe44f381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 114:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54192f39a1e04bf1a0d3f37d1a12402e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 115:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b5c8c7330b4029b6b15a88d5ac044d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 116:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e62185000c448c9e5e49c2af0a3c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 117:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa95e7e2b56647feaf03484c62598974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 118:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dd25967557499caf1bcf3f22a0d5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 119:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037e706d54e64e08a32cdd65fd6fba2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 120:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1313e69b4f524d349863b582ab1aee50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 121:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e42e8ad2ca44a5ac3c65a5846a16d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 122:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2248fdcd034d64ba43c9ef2dd028b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 123:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8adba8ea2dd4143934b8c194fccf406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 124:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ac5d0d50874c49afa8702f9cfb9648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "acc            Batch 125:    0%|| 0/2 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# <-- Your training loop in action!\u001b[39;00m\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds to train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/trainer/trainer.py:2297\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_dataloader, train_dataloader_label, train_subset_num_batches, spin_dataloaders, duration, reset_time, schedulers, scale_schedule_ratio, step_schedulers_every_batch, eval_dataloader, eval_subset_num_batches, eval_interval, device_train_microbatch_size, precision)\u001b[0m\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m ClosureGradScaler() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_closures() \u001b[38;5;28;01melse\u001b[39;00m GradScaler()\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_train_batch_complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2297\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[38;5;66;03m# Zero gradients at the end of fit so same model/optimizer can be used for further training\u001b[39;00m\n\u001b[1;32m   2300\u001b[0m \u001b[38;5;66;03m# with checkpoint loading. See https://github.com/pytorch/pytorch/issues/133415\u001b[39;00m\n\u001b[1;32m   2301\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optimizer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moptimizers:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/trainer/trainer.py:2507\u001b[0m, in \u001b[0;36mTrainer._train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2504\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_metrics({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime/token\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimestamp\u001b[38;5;241m.\u001b[39mtoken\u001b[38;5;241m.\u001b[39mvalue})\n\u001b[1;32m   2505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_metrics({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime/token_in_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimestamp\u001b[38;5;241m.\u001b[39mtoken_in_epoch\u001b[38;5;241m.\u001b[39mvalue})\n\u001b[0;32m-> 2507\u001b[0m total_loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_grad_scaling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_grad_scaling:\n\u001b[1;32m   2510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/trainer/trainer.py:2732\u001b[0m, in \u001b[0;36mTrainer._train_batch\u001b[0;34m(self, use_grad_scaling)\u001b[0m\n\u001b[1;32m   2726\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(\n\u001b[1;32m   2727\u001b[0m                 optimizer,\n\u001b[1;32m   2728\u001b[0m                 closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m loss_dict\u001b[38;5;241m=\u001b[39mtotal_loss_dict,\n\u001b[1;32m   2729\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_microbatches(microbatches, loss_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m   2730\u001b[0m             )\n\u001b[1;32m   2731\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2732\u001b[0m             \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[43m                \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_loss_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2734\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_microbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmicrobatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2735\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_microbatches(microbatches, total_loss_dict)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/optim/lr_scheduler.py:140\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    139\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/optim/decoupled_weight_decay.py:308\u001b[0m, in \u001b[0;36mDecoupledAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 308\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    311\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/trainer/trainer.py:2734\u001b[0m, in \u001b[0;36mTrainer._train_batch.<locals>.<lambda>\u001b[0;34m(loss_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2726\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(\n\u001b[1;32m   2727\u001b[0m                 optimizer,\n\u001b[1;32m   2728\u001b[0m                 closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m loss_dict\u001b[38;5;241m=\u001b[39mtotal_loss_dict,\n\u001b[1;32m   2729\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_microbatches(microbatches, loss_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m   2730\u001b[0m             )\n\u001b[1;32m   2731\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2732\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep(\n\u001b[1;32m   2733\u001b[0m                 closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m loss_dict\u001b[38;5;241m=\u001b[39mtotal_loss_dict,\n\u001b[0;32m-> 2734\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_microbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmicrobatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m   2735\u001b[0m             )\n\u001b[1;32m   2736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_microbatches(microbatches, total_loss_dict)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/trainer/trainer.py:2897\u001b[0m, in \u001b[0;36mTrainer._train_microbatches\u001b[0;34m(self, microbatches, total_loss_dict, ddp_sync)\u001b[0m\n\u001b[1;32m   2895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_data_spec\u001b[38;5;241m.\u001b[39mmicrobatch_transforms(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m   2896\u001b[0m is_final_microbatch \u001b[38;5;241m=\u001b[39m microbatch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(microbatches)\n\u001b[0;32m-> 2897\u001b[0m microbatch_loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_microbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_grad_scaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_final_microbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2899\u001b[0m \u001b[38;5;66;03m# Aggregate each loss in microbatch_loss_dict into total_loss_dict\u001b[39;00m\n\u001b[1;32m   2900\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, microbatch_loss \u001b[38;5;129;01min\u001b[39;00m microbatch_loss_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/trainer/trainer.py:3054\u001b[0m, in \u001b[0;36mTrainer._train_microbatch\u001b[0;34m(self, use_grad_scaling, current_batch_size, is_final_microbatch)\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3050\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtrain_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnnecessaryComparison]\u001b[39;00m\n\u001b[1;32m   3051\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtrain_metrics) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3052\u001b[0m     ):\n\u001b[1;32m   3053\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtrain_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_metrics_device_and_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtrain_metrics)\n\u001b[0;32m-> 3054\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_train_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m microbatch_loss_dict\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/trainer/trainer.py:2657\u001b[0m, in \u001b[0;36mTrainer._eval_train_metrics\u001b[0;34m(self, device_batch)\u001b[0m\n\u001b[1;32m   2655\u001b[0m eval_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_model\u001b[38;5;241m.\u001b[39meval_forward(device_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutputs)\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtrain_metrics\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m-> 2657\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_original_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2659\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/models/huggingface.py:588\u001b[0m, in \u001b[0;36mHuggingFaceModel.update_metric\u001b[0;34m(self, batch, outputs, metric)\u001b[0m\n\u001b[1;32m    586\u001b[0m     metric_result \u001b[38;5;241m=\u001b[39m metric\u001b[38;5;241m.\u001b[39mupdate(batch\u001b[38;5;241m=\u001b[39mbatch, outputs\u001b[38;5;241m=\u001b[39moutputs, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 588\u001b[0m     metric_result \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;66;03m# Add the metric name once for each datapoint in the batch\u001b[39;00m\n\u001b[1;32m    591\u001b[0m     metric_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [metric\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torchmetrics/metric.py:550\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/composer/metrics/nlp.py:59\u001b[0m, in \u001b[0;36mMaskedAccuracy.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorrect, Tensor)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal, Tensor)\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorrect \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmasked_preds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmasked_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.perf_counter()\n",
    "trainer.fit() # <-- Your training loop in action!\n",
    "end_time = time.perf_counter()\n",
    "print(f\"It took {end_time - start_time:0.4f} seconds to train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['time/epoch', 'time/batch', 'time/sample', 'time/batch_in_epoch', 'time/sample_in_epoch', 'time/token', 'time/token_in_epoch', 'trainer/device_train_microbatch_size', 'loss/train/total', 'metrics/train/MaskedAccuracy', 'metrics/train/LanguageCrossEntropy', 'trainer/acc/device_eval_microbatch_size', 'metrics/acc/MaskedAccuracy', 'metrics/acc/LanguageCrossEntropy'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, tokenizer, prompt, max_length=50, device='cpu'):\n",
    "    with torch.autocast('cuda', torch.bfloat16):\n",
    "        input_ids = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "        model.eval()\n",
    "        output = model.generate(**input_ids, max_length=max_length, do_sample=True, top_k=50, top_p=0.95, temperature=0.8)\n",
    "        return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lily. She loved to play outside in the sun. One day, she saw a little boy sitting on a bench. The boy was very sad and wanted to help her. \n",
      "\n",
      "Lily wanted to play with the boy and play with her. But the boy tried to catch the boy. She asked her, \"Can I have a lab I?\" The little boy said, \"No, I want to play with you.\" \n",
      "\n",
      "Lily started to cry and said, \"I just want to play with you. Can I play with me?\" The boy replied, \"Sure, I will catch you.\" The boy smiled and said, \"That is my best thing to play with me.\"Once upon a time, there was a little boy named Timmy. Timmy loved to go outside in his room. One day, he was playing in the garden when he saw a big red stone in the air. It was a big box with long hair. Timmy was scared, but then he ran towards the box.\n",
      "\n",
      "Timmy saw the stone on the box and said, \"Let's go in and look for a pretty stone.\" Timmy's mommy said, \"Okay, we can buy some stone.\"\n",
      "\n",
      "After the bottraade, Timmy got some juice and a big pile of wheels. He was so happy and gave his hand. He went to his mom and said, \"Thank you for being so lucky to be my best friend!\"Once upon a time, there was a little girl named Lily. She loved to play outside in her garden. One day, she saw a big, brown bear named Bun. Bun was very small and had many fun.\n",
      "\n",
      "Lily asked Bun, \"What is this?\" Bun said, \"I don't know that means.\"\n",
      "\n",
      "Lily thought about it if he was there, so she said, \"I will show you how to make you look for you. Please help me?\"\n",
      "\n",
      "Lily smiled and said, \"Sure, I can do with my sweet cheese, so I will help you.\" She was so happy and said, \"Thank you for playing with me, Bunn.\" And they both had a great day in the park.Once upon a time, there was a little girl named Lily. She loved to play outside with her friends. One day, she found a pretty flower\n"
     ]
    }
   ],
   "source": [
    "print(sample(my_model, tokenizer, \"Once upon a time\", max_length=500, device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['time/epoch', 'time/batch', 'time/sample', 'time/batch_in_epoch', 'time/sample_in_epoch', 'time/token', 'time/token_in_epoch', 'trainer/device_train_microbatch_size', 'loss/train/total', 'metrics/train/MaskedAccuracy', 'metrics/train/LanguageCrossEntropy'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract time and loss values\n",
    "time_values = []\n",
    "loss_values = []\n",
    "for t, v in logger.data['metrics/acc/LanguageCrossEntropy']:\n",
    "    time_values.append(t.batch.value)\n",
    "    loss_values.append(v.cpu().data)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_values, loss_values)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaskedAccuracy' object has no attribute 'sum_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum_loss\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaskedAccuracy' object has no attribute 'sum_loss'"
     ]
    }
   ],
   "source": [
    "metrics[0].sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls training/pretrain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.optim import DecoupledAdamW, CosineAnnealingWithWarmupScheduler\n",
    "from composer.loggers import InMemoryLogger\n",
    "from composer.metrics import MaskedAccuracy\n",
    "\n",
    "optim = DecoupledAdamW(my_model.parameters(), lr=2e-4, weight_decay=0.0001)\n",
    "lr_scheduler = CosineAnnealingWithWarmupScheduler(t_warmup='200ba', t_max=\"1dur\")\n",
    "\n",
    "logger = InMemoryLogger()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=my_model,\n",
    "    train_dataloader=dl_train, \n",
    "    eval_dataloader=eval_evaluator,\n",
    "    optimizers=optim,\n",
    "    schedulers=lr_scheduler,\n",
    "    max_duration=\"2ep\",\n",
    "    eval_interval='1000ba',\n",
    "    save_folder=\"training/pretrain/compile/\" + str(optim.param_groups[0]['lr']),\n",
    "    save_interval=\"5000ba\",\n",
    "    save_filename=\"hf_model.pt\",\n",
    "    save_overwrite=True,\n",
    "    device_train_microbatch_size='auto',\n",
    "    loggers=logger,\n",
    "    device='gpu',\n",
    "    precision='amp_bf16',\n",
    "    autoresume=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
